{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valy3124/Data-Science-Medical-DL/blob/main/Lab_03_CNN_Architectures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo1ztV4wMm7H"
      },
      "source": [
        "# CNN Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xScZXeqMqHk"
      },
      "source": [
        "#### Motivation\n",
        "In the previous Lab we saw that it is difficult to construct a custom CNN for specific tasks as we have to experiment with many hyperparameters (number of layers, number of feature maps per layer, kernel sizes, fully connected network configuration, etc.)\n",
        "\n",
        "Luckily we do not have to do that. There are plenty of architectures that have been constructed and tested for many tasks.\n",
        "\n",
        "With very minor changes, we can adapt existing architectures to our task and be relatively confident that it will obtain good results (if trained correctly).\n",
        "\n",
        "In Lab 3 you will learn how to utilize available architectures and how to fine-tune them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOqN0dbL629N"
      },
      "source": [
        "#### Notes\n",
        "As we utilize deep networks, training will take quite a long time in this lab. Running on GPU is necessary (Runtime -> Change Runtime Type).\n",
        "\n",
        "If you see that a run is not going anywhere (Validation Accuracy is not increasing or Loss is not decreasing) cancel it to save some time.\n",
        "\n",
        "If possible, run the training with higher batch sizes to speed up the training.\n",
        "\n",
        "While the models are training, we recommend that you look over the papers of the architectures.ðŸ˜„"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z54LucfQwgJ"
      },
      "source": [
        "#### Libraries\n",
        "There are plenty of architectures available in the [torchvision library](https://pytorch.org/vision/0.8/models.html), the [timm library](https://timm.fast.ai/), and on [Hugging Face](https://huggingface.co/models?pipeline_tag=image-classification&sort=downloads)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPMMdBmMeaJ2"
      },
      "source": [
        "### Training an off-the-shelf model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UNuZ77zgLXAW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRbe3lPneiBK"
      },
      "source": [
        "We will use the CIFAR10 dataset as in the previous lab. Let's see if we can obtain better results this time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IGJPOIhDeg8r",
        "outputId": "0eb13b59-79b2-4012-8d0e-80c609baa4d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:11<00:00, 14.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_transform = transforms.Compose(\n",
        "    [\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "test_transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "\n",
        "# The batch size is the number of images the model processes in parallel\n",
        "# We use shuffle for training as we don't want the model to see the images in the same order\n",
        "trainloader = DataLoader(trainset, batch_size=256,\n",
        "                                          shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "\n",
        "# For testing we don't have to shuffle the data\n",
        "testloader = DataLoader(testset, batch_size=256,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksE1R1Sdev_s"
      },
      "source": [
        "Code for training and validation - same as in previous lab\n",
        "\n",
        "You should already be familiar with the following blocks of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_24CNaNHe2DK"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o4j81PNAe3oC"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, dataloader, device, optimizer, criterion, epoch):\n",
        "    # We set the model to be in training mode\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0.0\n",
        "    dataset_size = 0\n",
        "\n",
        "    # This is only for showing the progress bar\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n",
        "\n",
        "    # We iterate through all batches - 1 step is 1 batch of batch_size images\n",
        "    for step, (images, labels) in bar:\n",
        "        # We take the images and their labels and push them on GPU\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Obtain predictions\n",
        "        pred = model(images)\n",
        "\n",
        "        # Compute loss for this batch\n",
        "        loss = criterion(pred, labels)\n",
        "\n",
        "        # Compute gradients for each weight (backpropagation)\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights based on gradients (gradient descent)\n",
        "        optimizer.step()\n",
        "\n",
        "        # We keep track of the average training loss\n",
        "        total_train_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = np.round(total_train_loss / dataset_size, 2)\n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss)\n",
        "\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oFcj3zd2e6Gk"
      },
      "outputs": [],
      "source": [
        "def valid_epoch(model, dataloader, device, criterion, epoch):\n",
        "    # We set the model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    total_val_loss = 0.0\n",
        "    dataset_size = 0\n",
        "\n",
        "    # We keep track of correct predictions\n",
        "    correct = 0\n",
        "\n",
        "    # This is only for showing the progress bar\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n",
        "\n",
        "    for step, (images, labels) in bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        pred = model(images)\n",
        "        loss = criterion(pred, labels)\n",
        "\n",
        "        # The raw output of the model is a score for each class\n",
        "        # We keep the index of the class with the highest score as the prediction\n",
        "        _, predicted = torch.max(pred, 1)\n",
        "\n",
        "        # We see how many predictions match the ground truth labels\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # We compute evaluation metrics - loss and accurarcy\n",
        "        total_val_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = np.round(total_val_loss / dataset_size, 2)\n",
        "\n",
        "        accuracy = np.round(100 * correct / dataset_size, 2)\n",
        "\n",
        "        bar.set_postfix(Epoch=epoch, Valid_Acc=accuracy, Valid_Loss=epoch_loss)\n",
        "\n",
        "    return accuracy, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J0KULbF2e9Nk"
      },
      "outputs": [],
      "source": [
        "def run_training(model, num_epochs, learning_rate):\n",
        "    # Define criterion\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Define optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Check if we are using GPU\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    # For keeping track of the best validation accuracy\n",
        "    top_accuracy = 0.0\n",
        "\n",
        "    # We train the emodel for a number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_loss = train_epoch(model, trainloader, device, optimizer, criterion, epoch)\n",
        "\n",
        "        # For validation we do not keep track of gradients\n",
        "        with torch.no_grad():\n",
        "            val_accuracy, val_loss = valid_epoch(model, testloader, device, criterion, epoch)\n",
        "            if val_accuracy > top_accuracy:\n",
        "                print(f\"Validation Accuracy Improved ({top_accuracy} ---> {val_accuracy})\")\n",
        "                top_accuracy = val_accuracy\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfjRk3fwfAJy"
      },
      "source": [
        "Code for counting number of parameters of a model.\n",
        "\n",
        "As we have limited compute resources, we will opt for models with fewer parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_Q8glR5ufPXg"
      },
      "outputs": [],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SqueezeNet from torchvision"
      ],
      "metadata": {
        "id": "FwfSmbgDjiXu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeQy1M-6fgdy"
      },
      "source": [
        "First, let's experiment with a model from the torchvision library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oVGd4_eDffl5"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdVMox4of9v9"
      },
      "source": [
        "Let's see what models are available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVPFefxWf_qC"
      },
      "outputs": [],
      "source": [
        "models.list_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr8b9HO7gSha"
      },
      "source": [
        "We will choose SqueezeNet which is a very lightweight model. More details about the architecture can be found in this [paper](https://arxiv.org/abs/1602.07360).\n",
        "\n",
        "<img src=https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-26_at_6.04.32_PM.png width=750px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wNDDxD9ugVY3",
        "outputId": "4d230e8e-01e6-4b85-9802-b4148f89b261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SqueezeNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (3): Fire(\n",
            "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Fire(\n",
            "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Fire(\n",
            "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (7): Fire(\n",
            "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): Fire(\n",
            "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): Fire(\n",
            "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (10): Fire(\n",
            "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "    (12): Fire(\n",
            "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (squeeze_activation): ReLU(inplace=True)\n",
            "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (expand1x1_activation): ReLU(inplace=True)\n",
            "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (expand3x3_activation): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            ")\n",
            "Number of parameters: 1248424\n"
          ]
        }
      ],
      "source": [
        "squeeze_net = models.squeezenet1_0()\n",
        "print(squeeze_net)\n",
        "print(\"Number of parameters:\", count_parameters(squeeze_net))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of modifying prediction head. In our case, we only change the final output layer.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/0*8Z3To8OAwBBIj66p.jpg\" width=700px>"
      ],
      "metadata": {
        "id": "4amQ6X2oihM7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bnAUzvhhaqb"
      },
      "source": [
        "The classifier is built for 1000 classes as it was intended for training on ImageNet. We have to modify it to work on 10 classes. Notice that the number of parameters changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QYAl9idzhkyy",
        "outputId": "b2a76b03-a678-4def-f180-27ae006eaa7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 740554\n"
          ]
        }
      ],
      "source": [
        "squeeze_net.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1,1), stride=(1,1))\n",
        "squeeze_net.to(device)\n",
        "print(\"Number of parameters:\", count_parameters(squeeze_net))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IREYZYpiF0Sg"
      },
      "source": [
        "We run the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "78uoDbL0h_RU",
        "outputId": "b0ff1ca4-98b6-4a75-e2a1-b6e1eedece1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 196/196 [01:43<00:00,  1.89it/s, Epoch=0, Train_Loss=2.06]\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 40/40 [00:11<00:00,  3.57it/s, Epoch=0, Valid_Acc=31.8, Valid_Loss=1.88]\n",
            "Validation Accuracy Improved (0.0 ---> 31.82)\n",
            "\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 196/196 [01:43<00:00,  1.90it/s, Epoch=1, Train_Loss=1.84]\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 40/40 [00:11<00:00,  3.58it/s, Epoch=1, Valid_Acc=38, Valid_Loss=1.77]\n",
            "Validation Accuracy Improved (31.82 ---> 37.97)\n",
            "\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 196/196 [01:42<00:00,  1.91it/s, Epoch=2, Train_Loss=1.7]\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 40/40 [00:11<00:00,  3.55it/s, Epoch=2, Valid_Acc=45.3, Valid_Loss=1.57]\n",
            "Validation Accuracy Improved (37.97 ---> 45.29)\n",
            "\n",
            " 93%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž\u001b[0m| 182/196 [01:35<00:07,  1.90it/s, Epoch=3, Train_Loss=1.56]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bdfe8ee5172e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You may want to change the hyperparameters to obtain better results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-417fcf9f7dcc>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# For validation we do not keep track of gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-912af7791e15>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, device, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Compute gradients for each weight (backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Update weights based on gradients (gradient descent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# You may want to change the hyperparameters to obtain better results\n",
        "run_training(model=squeeze_net, num_epochs=10, learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning pre-trained model"
      ],
      "metadata": {
        "id": "ILDTtPWMjOmY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mmKqF5GjxpE"
      },
      "source": [
        "The performance is not that impressive. You could improve the results by playing with the learning rate, number of epochs, and add image augmentations.\n",
        "\n",
        "However, we do not have to start from randomly initialized weights.\n",
        "\n",
        "We can start from weights pre-trained on large datasets (ImageNet) and fine-tune the weights on the new task.\n",
        "\n",
        "This is simply done by specifying :```pretrained=True``` when initializing the model\n",
        "\n",
        "This should improve the performance as the convolutional layers have already learnt to extract meaningful features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oVFJIMqwj6Hv",
        "outputId": "87b1025d-f0ad-49eb-ed8c-e422c5739782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_0-b66bff10.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_0-b66bff10.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.78M/4.78M [00:00<00:00, 81.6MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SqueezeNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (3): Fire(\n",
              "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Fire(\n",
              "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Fire(\n",
              "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (7): Fire(\n",
              "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): Fire(\n",
              "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): Fire(\n",
              "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): Fire(\n",
              "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "    (12): Fire(\n",
              "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "squeeze_net = models.squeezenet1_0(pretrained=True)\n",
        "squeeze_net.classifier[1] = nn.Conv2d(512, 10, kernel_size=(1,1), stride=(1,1))\n",
        "squeeze_net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "80bdocJ5kWzY",
        "outputId": "3a49cedc-488f-44f6-da20-22cb672b8bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 196/196 [01:44<00:00,  1.87it/s, Epoch=0, Train_Loss=2.15]\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 40/40 [00:11<00:00,  3.55it/s, Epoch=0, Valid_Acc=52.7, Valid_Loss=1.4]\n",
            "Validation Accuracy Improved (0.0 ---> 52.73)\n",
            "\n",
            " 11%|\u001b[36mâ–ˆ         \u001b[0m| 21/196 [00:11<01:38,  1.77it/s, Epoch=1, Train_Loss=1.42]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6889d66b3583>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Usually when we fine-tune pretrained models we utilize lower learning rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-417fcf9f7dcc>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# For validation we do not keep track of gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-912af7791e15>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, device, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Compute gradients for each weight (backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Update weights based on gradients (gradient descent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Usually when we fine-tune pretrained models we utilize lower learning rates\n",
        "run_training(model=squeeze_net, num_epochs=10, learning_rate=0.0003)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV2zfrYI629Q"
      },
      "source": [
        "The model should obtain better results."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet-18 from timm library"
      ],
      "metadata": {
        "id": "MixNQlhUjvoM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N14ES_v-m_zl"
      },
      "source": [
        "Let's try another model from a different library. We will use the timm library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3okAqrq6nF57",
        "outputId": "4da749dd-b0e4-4a1b-e7e4-fa762b062b70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mXnc0dzJnKax"
      },
      "outputs": [],
      "source": [
        "import timm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gseg32BHnL-Y"
      },
      "source": [
        "Let's see available models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SFC8BrThnNnu",
        "outputId": "6a14b77f-b21c-47d0-9c78-4ffc77be312b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bat_resnext26ts',\n",
              " 'beit_base_patch16_224',\n",
              " 'beit_base_patch16_384',\n",
              " 'beit_large_patch16_224',\n",
              " 'beit_large_patch16_384',\n",
              " 'beit_large_patch16_512',\n",
              " 'beitv2_base_patch16_224',\n",
              " 'beitv2_large_patch16_224',\n",
              " 'botnet26t_256',\n",
              " 'botnet50ts_256',\n",
              " 'caformer_b36',\n",
              " 'caformer_m36',\n",
              " 'caformer_s18',\n",
              " 'caformer_s36',\n",
              " 'cait_m36_384',\n",
              " 'cait_m48_448',\n",
              " 'cait_s24_224',\n",
              " 'cait_s24_384',\n",
              " 'cait_s36_384',\n",
              " 'cait_xs24_384',\n",
              " 'cait_xxs24_224',\n",
              " 'cait_xxs24_384',\n",
              " 'cait_xxs36_224',\n",
              " 'cait_xxs36_384',\n",
              " 'coat_lite_medium',\n",
              " 'coat_lite_medium_384',\n",
              " 'coat_lite_mini',\n",
              " 'coat_lite_small',\n",
              " 'coat_lite_tiny',\n",
              " 'coat_mini',\n",
              " 'coat_small',\n",
              " 'coat_tiny',\n",
              " 'coatnet_0_224',\n",
              " 'coatnet_0_rw_224',\n",
              " 'coatnet_1_224',\n",
              " 'coatnet_1_rw_224',\n",
              " 'coatnet_2_224',\n",
              " 'coatnet_2_rw_224',\n",
              " 'coatnet_3_224',\n",
              " 'coatnet_3_rw_224',\n",
              " 'coatnet_4_224',\n",
              " 'coatnet_5_224',\n",
              " 'coatnet_bn_0_rw_224',\n",
              " 'coatnet_nano_cc_224',\n",
              " 'coatnet_nano_rw_224',\n",
              " 'coatnet_pico_rw_224',\n",
              " 'coatnet_rmlp_0_rw_224',\n",
              " 'coatnet_rmlp_1_rw2_224',\n",
              " 'coatnet_rmlp_1_rw_224',\n",
              " 'coatnet_rmlp_2_rw_224',\n",
              " 'coatnet_rmlp_2_rw_384',\n",
              " 'coatnet_rmlp_3_rw_224',\n",
              " 'coatnet_rmlp_nano_rw_224',\n",
              " 'coatnext_nano_rw_224',\n",
              " 'convformer_b36',\n",
              " 'convformer_m36',\n",
              " 'convformer_s18',\n",
              " 'convformer_s36',\n",
              " 'convit_base',\n",
              " 'convit_small',\n",
              " 'convit_tiny',\n",
              " 'convmixer_768_32',\n",
              " 'convmixer_1024_20_ks9_p14',\n",
              " 'convmixer_1536_20',\n",
              " 'convnext_atto',\n",
              " 'convnext_atto_ols',\n",
              " 'convnext_atto_rms',\n",
              " 'convnext_base',\n",
              " 'convnext_femto',\n",
              " 'convnext_femto_ols',\n",
              " 'convnext_large',\n",
              " 'convnext_large_mlp',\n",
              " 'convnext_nano',\n",
              " 'convnext_nano_ols',\n",
              " 'convnext_pico',\n",
              " 'convnext_pico_ols',\n",
              " 'convnext_small',\n",
              " 'convnext_tiny',\n",
              " 'convnext_tiny_hnf',\n",
              " 'convnext_xlarge',\n",
              " 'convnext_xxlarge',\n",
              " 'convnext_zepto_rms',\n",
              " 'convnext_zepto_rms_ols',\n",
              " 'convnextv2_atto',\n",
              " 'convnextv2_base',\n",
              " 'convnextv2_femto',\n",
              " 'convnextv2_huge',\n",
              " 'convnextv2_large',\n",
              " 'convnextv2_nano',\n",
              " 'convnextv2_pico',\n",
              " 'convnextv2_small',\n",
              " 'convnextv2_tiny',\n",
              " 'crossvit_9_240',\n",
              " 'crossvit_9_dagger_240',\n",
              " 'crossvit_15_240',\n",
              " 'crossvit_15_dagger_240',\n",
              " 'crossvit_15_dagger_408',\n",
              " 'crossvit_18_240',\n",
              " 'crossvit_18_dagger_240',\n",
              " 'crossvit_18_dagger_408',\n",
              " 'crossvit_base_240',\n",
              " 'crossvit_small_240',\n",
              " 'crossvit_tiny_240',\n",
              " 'cs3darknet_focus_l',\n",
              " 'cs3darknet_focus_m',\n",
              " 'cs3darknet_focus_s',\n",
              " 'cs3darknet_focus_x',\n",
              " 'cs3darknet_l',\n",
              " 'cs3darknet_m',\n",
              " 'cs3darknet_s',\n",
              " 'cs3darknet_x',\n",
              " 'cs3edgenet_x',\n",
              " 'cs3se_edgenet_x',\n",
              " 'cs3sedarknet_l',\n",
              " 'cs3sedarknet_x',\n",
              " 'cs3sedarknet_xdw',\n",
              " 'cspdarknet53',\n",
              " 'cspresnet50',\n",
              " 'cspresnet50d',\n",
              " 'cspresnet50w',\n",
              " 'cspresnext50',\n",
              " 'darknet17',\n",
              " 'darknet21',\n",
              " 'darknet53',\n",
              " 'darknetaa53',\n",
              " 'davit_base',\n",
              " 'davit_base_fl',\n",
              " 'davit_giant',\n",
              " 'davit_huge',\n",
              " 'davit_huge_fl',\n",
              " 'davit_large',\n",
              " 'davit_small',\n",
              " 'davit_tiny',\n",
              " 'deit3_base_patch16_224',\n",
              " 'deit3_base_patch16_384',\n",
              " 'deit3_huge_patch14_224',\n",
              " 'deit3_large_patch16_224',\n",
              " 'deit3_large_patch16_384',\n",
              " 'deit3_medium_patch16_224',\n",
              " 'deit3_small_patch16_224',\n",
              " 'deit3_small_patch16_384',\n",
              " 'deit_base_distilled_patch16_224',\n",
              " 'deit_base_distilled_patch16_384',\n",
              " 'deit_base_patch16_224',\n",
              " 'deit_base_patch16_384',\n",
              " 'deit_small_distilled_patch16_224',\n",
              " 'deit_small_patch16_224',\n",
              " 'deit_tiny_distilled_patch16_224',\n",
              " 'deit_tiny_patch16_224',\n",
              " 'densenet121',\n",
              " 'densenet161',\n",
              " 'densenet169',\n",
              " 'densenet201',\n",
              " 'densenet264d',\n",
              " 'densenetblur121d',\n",
              " 'dla34',\n",
              " 'dla46_c',\n",
              " 'dla46x_c',\n",
              " 'dla60',\n",
              " 'dla60_res2net',\n",
              " 'dla60_res2next',\n",
              " 'dla60x',\n",
              " 'dla60x_c',\n",
              " 'dla102',\n",
              " 'dla102x',\n",
              " 'dla102x2',\n",
              " 'dla169',\n",
              " 'dm_nfnet_f0',\n",
              " 'dm_nfnet_f1',\n",
              " 'dm_nfnet_f2',\n",
              " 'dm_nfnet_f3',\n",
              " 'dm_nfnet_f4',\n",
              " 'dm_nfnet_f5',\n",
              " 'dm_nfnet_f6',\n",
              " 'dpn48b',\n",
              " 'dpn68',\n",
              " 'dpn68b',\n",
              " 'dpn92',\n",
              " 'dpn98',\n",
              " 'dpn107',\n",
              " 'dpn131',\n",
              " 'eca_botnext26ts_256',\n",
              " 'eca_halonext26ts',\n",
              " 'eca_nfnet_l0',\n",
              " 'eca_nfnet_l1',\n",
              " 'eca_nfnet_l2',\n",
              " 'eca_nfnet_l3',\n",
              " 'eca_resnet33ts',\n",
              " 'eca_resnext26ts',\n",
              " 'eca_vovnet39b',\n",
              " 'ecaresnet26t',\n",
              " 'ecaresnet50d',\n",
              " 'ecaresnet50d_pruned',\n",
              " 'ecaresnet50t',\n",
              " 'ecaresnet101d',\n",
              " 'ecaresnet101d_pruned',\n",
              " 'ecaresnet200d',\n",
              " 'ecaresnet269d',\n",
              " 'ecaresnetlight',\n",
              " 'ecaresnext26t_32x4d',\n",
              " 'ecaresnext50t_32x4d',\n",
              " 'edgenext_base',\n",
              " 'edgenext_small',\n",
              " 'edgenext_small_rw',\n",
              " 'edgenext_x_small',\n",
              " 'edgenext_xx_small',\n",
              " 'efficientformer_l1',\n",
              " 'efficientformer_l3',\n",
              " 'efficientformer_l7',\n",
              " 'efficientformerv2_l',\n",
              " 'efficientformerv2_s0',\n",
              " 'efficientformerv2_s1',\n",
              " 'efficientformerv2_s2',\n",
              " 'efficientnet_b0',\n",
              " 'efficientnet_b0_g8_gn',\n",
              " 'efficientnet_b0_g16_evos',\n",
              " 'efficientnet_b0_gn',\n",
              " 'efficientnet_b1',\n",
              " 'efficientnet_b1_pruned',\n",
              " 'efficientnet_b2',\n",
              " 'efficientnet_b2_pruned',\n",
              " 'efficientnet_b3',\n",
              " 'efficientnet_b3_g8_gn',\n",
              " 'efficientnet_b3_gn',\n",
              " 'efficientnet_b3_pruned',\n",
              " 'efficientnet_b4',\n",
              " 'efficientnet_b5',\n",
              " 'efficientnet_b6',\n",
              " 'efficientnet_b7',\n",
              " 'efficientnet_b8',\n",
              " 'efficientnet_blur_b0',\n",
              " 'efficientnet_cc_b0_4e',\n",
              " 'efficientnet_cc_b0_8e',\n",
              " 'efficientnet_cc_b1_8e',\n",
              " 'efficientnet_el',\n",
              " 'efficientnet_el_pruned',\n",
              " 'efficientnet_em',\n",
              " 'efficientnet_es',\n",
              " 'efficientnet_es_pruned',\n",
              " 'efficientnet_h_b5',\n",
              " 'efficientnet_l2',\n",
              " 'efficientnet_lite0',\n",
              " 'efficientnet_lite1',\n",
              " 'efficientnet_lite2',\n",
              " 'efficientnet_lite3',\n",
              " 'efficientnet_lite4',\n",
              " 'efficientnet_x_b3',\n",
              " 'efficientnet_x_b5',\n",
              " 'efficientnetv2_l',\n",
              " 'efficientnetv2_m',\n",
              " 'efficientnetv2_rw_m',\n",
              " 'efficientnetv2_rw_s',\n",
              " 'efficientnetv2_rw_t',\n",
              " 'efficientnetv2_s',\n",
              " 'efficientnetv2_xl',\n",
              " 'efficientvit_b0',\n",
              " 'efficientvit_b1',\n",
              " 'efficientvit_b2',\n",
              " 'efficientvit_b3',\n",
              " 'efficientvit_l1',\n",
              " 'efficientvit_l2',\n",
              " 'efficientvit_l3',\n",
              " 'efficientvit_m0',\n",
              " 'efficientvit_m1',\n",
              " 'efficientvit_m2',\n",
              " 'efficientvit_m3',\n",
              " 'efficientvit_m4',\n",
              " 'efficientvit_m5',\n",
              " 'ese_vovnet19b_dw',\n",
              " 'ese_vovnet19b_slim',\n",
              " 'ese_vovnet19b_slim_dw',\n",
              " 'ese_vovnet39b',\n",
              " 'ese_vovnet39b_evos',\n",
              " 'ese_vovnet57b',\n",
              " 'ese_vovnet99b',\n",
              " 'eva02_base_patch14_224',\n",
              " 'eva02_base_patch14_448',\n",
              " 'eva02_base_patch16_clip_224',\n",
              " 'eva02_enormous_patch14_clip_224',\n",
              " 'eva02_large_patch14_224',\n",
              " 'eva02_large_patch14_448',\n",
              " 'eva02_large_patch14_clip_224',\n",
              " 'eva02_large_patch14_clip_336',\n",
              " 'eva02_small_patch14_224',\n",
              " 'eva02_small_patch14_336',\n",
              " 'eva02_tiny_patch14_224',\n",
              " 'eva02_tiny_patch14_336',\n",
              " 'eva_giant_patch14_224',\n",
              " 'eva_giant_patch14_336',\n",
              " 'eva_giant_patch14_560',\n",
              " 'eva_giant_patch14_clip_224',\n",
              " 'eva_large_patch14_196',\n",
              " 'eva_large_patch14_336',\n",
              " 'fastvit_ma36',\n",
              " 'fastvit_mci0',\n",
              " 'fastvit_mci1',\n",
              " 'fastvit_mci2',\n",
              " 'fastvit_s12',\n",
              " 'fastvit_sa12',\n",
              " 'fastvit_sa24',\n",
              " 'fastvit_sa36',\n",
              " 'fastvit_t8',\n",
              " 'fastvit_t12',\n",
              " 'fbnetc_100',\n",
              " 'fbnetv3_b',\n",
              " 'fbnetv3_d',\n",
              " 'fbnetv3_g',\n",
              " 'flexivit_base',\n",
              " 'flexivit_large',\n",
              " 'flexivit_small',\n",
              " 'focalnet_base_lrf',\n",
              " 'focalnet_base_srf',\n",
              " 'focalnet_huge_fl3',\n",
              " 'focalnet_huge_fl4',\n",
              " 'focalnet_large_fl3',\n",
              " 'focalnet_large_fl4',\n",
              " 'focalnet_small_lrf',\n",
              " 'focalnet_small_srf',\n",
              " 'focalnet_tiny_lrf',\n",
              " 'focalnet_tiny_srf',\n",
              " 'focalnet_xlarge_fl3',\n",
              " 'focalnet_xlarge_fl4',\n",
              " 'gc_efficientnetv2_rw_t',\n",
              " 'gcresnet33ts',\n",
              " 'gcresnet50t',\n",
              " 'gcresnext26ts',\n",
              " 'gcresnext50ts',\n",
              " 'gcvit_base',\n",
              " 'gcvit_small',\n",
              " 'gcvit_tiny',\n",
              " 'gcvit_xtiny',\n",
              " 'gcvit_xxtiny',\n",
              " 'gernet_l',\n",
              " 'gernet_m',\n",
              " 'gernet_s',\n",
              " 'ghostnet_050',\n",
              " 'ghostnet_100',\n",
              " 'ghostnet_130',\n",
              " 'ghostnetv2_100',\n",
              " 'ghostnetv2_130',\n",
              " 'ghostnetv2_160',\n",
              " 'gmixer_12_224',\n",
              " 'gmixer_24_224',\n",
              " 'gmlp_b16_224',\n",
              " 'gmlp_s16_224',\n",
              " 'gmlp_ti16_224',\n",
              " 'halo2botnet50ts_256',\n",
              " 'halonet26t',\n",
              " 'halonet50ts',\n",
              " 'halonet_h1',\n",
              " 'haloregnetz_b',\n",
              " 'hardcorenas_a',\n",
              " 'hardcorenas_b',\n",
              " 'hardcorenas_c',\n",
              " 'hardcorenas_d',\n",
              " 'hardcorenas_e',\n",
              " 'hardcorenas_f',\n",
              " 'hgnet_base',\n",
              " 'hgnet_small',\n",
              " 'hgnet_tiny',\n",
              " 'hgnetv2_b0',\n",
              " 'hgnetv2_b1',\n",
              " 'hgnetv2_b2',\n",
              " 'hgnetv2_b3',\n",
              " 'hgnetv2_b4',\n",
              " 'hgnetv2_b5',\n",
              " 'hgnetv2_b6',\n",
              " 'hiera_base_224',\n",
              " 'hiera_base_abswin_256',\n",
              " 'hiera_base_plus_224',\n",
              " 'hiera_huge_224',\n",
              " 'hiera_large_224',\n",
              " 'hiera_small_224',\n",
              " 'hiera_small_abswin_256',\n",
              " 'hiera_tiny_224',\n",
              " 'hieradet_small',\n",
              " 'hrnet_w18',\n",
              " 'hrnet_w18_small',\n",
              " 'hrnet_w18_small_v2',\n",
              " 'hrnet_w18_ssld',\n",
              " 'hrnet_w30',\n",
              " 'hrnet_w32',\n",
              " 'hrnet_w40',\n",
              " 'hrnet_w44',\n",
              " 'hrnet_w48',\n",
              " 'hrnet_w48_ssld',\n",
              " 'hrnet_w64',\n",
              " 'inception_next_base',\n",
              " 'inception_next_small',\n",
              " 'inception_next_tiny',\n",
              " 'inception_resnet_v2',\n",
              " 'inception_v3',\n",
              " 'inception_v4',\n",
              " 'lambda_resnet26rpt_256',\n",
              " 'lambda_resnet26t',\n",
              " 'lambda_resnet50ts',\n",
              " 'lamhalobotnet50ts_256',\n",
              " 'lcnet_035',\n",
              " 'lcnet_050',\n",
              " 'lcnet_075',\n",
              " 'lcnet_100',\n",
              " 'lcnet_150',\n",
              " 'legacy_senet154',\n",
              " 'legacy_seresnet18',\n",
              " 'legacy_seresnet34',\n",
              " 'legacy_seresnet50',\n",
              " 'legacy_seresnet101',\n",
              " 'legacy_seresnet152',\n",
              " 'legacy_seresnext26_32x4d',\n",
              " 'legacy_seresnext50_32x4d',\n",
              " 'legacy_seresnext101_32x4d',\n",
              " 'legacy_xception',\n",
              " 'levit_128',\n",
              " 'levit_128s',\n",
              " 'levit_192',\n",
              " 'levit_256',\n",
              " 'levit_256d',\n",
              " 'levit_384',\n",
              " 'levit_384_s8',\n",
              " 'levit_512',\n",
              " 'levit_512_s8',\n",
              " 'levit_512d',\n",
              " 'levit_conv_128',\n",
              " 'levit_conv_128s',\n",
              " 'levit_conv_192',\n",
              " 'levit_conv_256',\n",
              " 'levit_conv_256d',\n",
              " 'levit_conv_384',\n",
              " 'levit_conv_384_s8',\n",
              " 'levit_conv_512',\n",
              " 'levit_conv_512_s8',\n",
              " 'levit_conv_512d',\n",
              " 'mambaout_base',\n",
              " 'mambaout_base_plus_rw',\n",
              " 'mambaout_base_short_rw',\n",
              " 'mambaout_base_tall_rw',\n",
              " 'mambaout_base_wide_rw',\n",
              " 'mambaout_femto',\n",
              " 'mambaout_kobe',\n",
              " 'mambaout_small',\n",
              " 'mambaout_small_rw',\n",
              " 'mambaout_tiny',\n",
              " 'maxvit_base_tf_224',\n",
              " 'maxvit_base_tf_384',\n",
              " 'maxvit_base_tf_512',\n",
              " 'maxvit_large_tf_224',\n",
              " 'maxvit_large_tf_384',\n",
              " 'maxvit_large_tf_512',\n",
              " 'maxvit_nano_rw_256',\n",
              " 'maxvit_pico_rw_256',\n",
              " 'maxvit_rmlp_base_rw_224',\n",
              " 'maxvit_rmlp_base_rw_384',\n",
              " 'maxvit_rmlp_nano_rw_256',\n",
              " 'maxvit_rmlp_pico_rw_256',\n",
              " 'maxvit_rmlp_small_rw_224',\n",
              " 'maxvit_rmlp_small_rw_256',\n",
              " 'maxvit_rmlp_tiny_rw_256',\n",
              " 'maxvit_small_tf_224',\n",
              " 'maxvit_small_tf_384',\n",
              " 'maxvit_small_tf_512',\n",
              " 'maxvit_tiny_pm_256',\n",
              " 'maxvit_tiny_rw_224',\n",
              " 'maxvit_tiny_rw_256',\n",
              " 'maxvit_tiny_tf_224',\n",
              " 'maxvit_tiny_tf_384',\n",
              " 'maxvit_tiny_tf_512',\n",
              " 'maxvit_xlarge_tf_224',\n",
              " 'maxvit_xlarge_tf_384',\n",
              " 'maxvit_xlarge_tf_512',\n",
              " 'maxxvit_rmlp_nano_rw_256',\n",
              " 'maxxvit_rmlp_small_rw_256',\n",
              " 'maxxvit_rmlp_tiny_rw_256',\n",
              " 'maxxvitv2_nano_rw_256',\n",
              " 'maxxvitv2_rmlp_base_rw_224',\n",
              " 'maxxvitv2_rmlp_base_rw_384',\n",
              " 'maxxvitv2_rmlp_large_rw_224',\n",
              " 'mixer_b16_224',\n",
              " 'mixer_b32_224',\n",
              " 'mixer_l16_224',\n",
              " 'mixer_l32_224',\n",
              " 'mixer_s16_224',\n",
              " 'mixer_s32_224',\n",
              " 'mixnet_l',\n",
              " 'mixnet_m',\n",
              " 'mixnet_s',\n",
              " 'mixnet_xl',\n",
              " 'mixnet_xxl',\n",
              " 'mnasnet_050',\n",
              " 'mnasnet_075',\n",
              " 'mnasnet_100',\n",
              " 'mnasnet_140',\n",
              " 'mnasnet_small',\n",
              " 'mobilenet_edgetpu_100',\n",
              " 'mobilenet_edgetpu_v2_l',\n",
              " 'mobilenet_edgetpu_v2_m',\n",
              " 'mobilenet_edgetpu_v2_s',\n",
              " 'mobilenet_edgetpu_v2_xs',\n",
              " 'mobilenetv1_100',\n",
              " 'mobilenetv1_100h',\n",
              " 'mobilenetv1_125',\n",
              " 'mobilenetv2_035',\n",
              " 'mobilenetv2_050',\n",
              " 'mobilenetv2_075',\n",
              " 'mobilenetv2_100',\n",
              " 'mobilenetv2_110d',\n",
              " 'mobilenetv2_120d',\n",
              " 'mobilenetv2_140',\n",
              " 'mobilenetv3_large_075',\n",
              " 'mobilenetv3_large_100',\n",
              " 'mobilenetv3_large_150d',\n",
              " 'mobilenetv3_rw',\n",
              " 'mobilenetv3_small_050',\n",
              " 'mobilenetv3_small_075',\n",
              " 'mobilenetv3_small_100',\n",
              " 'mobilenetv4_conv_aa_large',\n",
              " 'mobilenetv4_conv_aa_medium',\n",
              " 'mobilenetv4_conv_blur_medium',\n",
              " 'mobilenetv4_conv_large',\n",
              " 'mobilenetv4_conv_medium',\n",
              " 'mobilenetv4_conv_small',\n",
              " 'mobilenetv4_conv_small_035',\n",
              " 'mobilenetv4_conv_small_050',\n",
              " 'mobilenetv4_hybrid_large',\n",
              " 'mobilenetv4_hybrid_large_075',\n",
              " 'mobilenetv4_hybrid_medium',\n",
              " 'mobilenetv4_hybrid_medium_075',\n",
              " 'mobileone_s0',\n",
              " 'mobileone_s1',\n",
              " 'mobileone_s2',\n",
              " 'mobileone_s3',\n",
              " 'mobileone_s4',\n",
              " 'mobilevit_s',\n",
              " 'mobilevit_xs',\n",
              " 'mobilevit_xxs',\n",
              " 'mobilevitv2_050',\n",
              " 'mobilevitv2_075',\n",
              " 'mobilevitv2_100',\n",
              " 'mobilevitv2_125',\n",
              " 'mobilevitv2_150',\n",
              " 'mobilevitv2_175',\n",
              " 'mobilevitv2_200',\n",
              " 'mvitv2_base',\n",
              " 'mvitv2_base_cls',\n",
              " 'mvitv2_huge_cls',\n",
              " 'mvitv2_large',\n",
              " 'mvitv2_large_cls',\n",
              " 'mvitv2_small',\n",
              " 'mvitv2_small_cls',\n",
              " 'mvitv2_tiny',\n",
              " 'nasnetalarge',\n",
              " 'nest_base',\n",
              " 'nest_base_jx',\n",
              " 'nest_small',\n",
              " 'nest_small_jx',\n",
              " 'nest_tiny',\n",
              " 'nest_tiny_jx',\n",
              " 'nextvit_base',\n",
              " 'nextvit_large',\n",
              " 'nextvit_small',\n",
              " 'nf_ecaresnet26',\n",
              " 'nf_ecaresnet50',\n",
              " 'nf_ecaresnet101',\n",
              " 'nf_regnet_b0',\n",
              " 'nf_regnet_b1',\n",
              " 'nf_regnet_b2',\n",
              " 'nf_regnet_b3',\n",
              " 'nf_regnet_b4',\n",
              " 'nf_regnet_b5',\n",
              " 'nf_resnet26',\n",
              " 'nf_resnet50',\n",
              " 'nf_resnet101',\n",
              " 'nf_seresnet26',\n",
              " 'nf_seresnet50',\n",
              " 'nf_seresnet101',\n",
              " 'nfnet_f0',\n",
              " 'nfnet_f1',\n",
              " 'nfnet_f2',\n",
              " 'nfnet_f3',\n",
              " 'nfnet_f4',\n",
              " 'nfnet_f5',\n",
              " 'nfnet_f6',\n",
              " 'nfnet_f7',\n",
              " 'nfnet_l0',\n",
              " 'pit_b_224',\n",
              " 'pit_b_distilled_224',\n",
              " 'pit_s_224',\n",
              " 'pit_s_distilled_224',\n",
              " 'pit_ti_224',\n",
              " 'pit_ti_distilled_224',\n",
              " 'pit_xs_224',\n",
              " 'pit_xs_distilled_224',\n",
              " 'pnasnet5large',\n",
              " 'poolformer_m36',\n",
              " 'poolformer_m48',\n",
              " 'poolformer_s12',\n",
              " 'poolformer_s24',\n",
              " 'poolformer_s36',\n",
              " 'poolformerv2_m36',\n",
              " 'poolformerv2_m48',\n",
              " 'poolformerv2_s12',\n",
              " 'poolformerv2_s24',\n",
              " 'poolformerv2_s36',\n",
              " 'pvt_v2_b0',\n",
              " 'pvt_v2_b1',\n",
              " 'pvt_v2_b2',\n",
              " 'pvt_v2_b2_li',\n",
              " 'pvt_v2_b3',\n",
              " 'pvt_v2_b4',\n",
              " 'pvt_v2_b5',\n",
              " 'rdnet_base',\n",
              " 'rdnet_large',\n",
              " 'rdnet_small',\n",
              " 'rdnet_tiny',\n",
              " 'regnetv_040',\n",
              " 'regnetv_064',\n",
              " 'regnetx_002',\n",
              " 'regnetx_004',\n",
              " 'regnetx_004_tv',\n",
              " 'regnetx_006',\n",
              " 'regnetx_008',\n",
              " 'regnetx_016',\n",
              " 'regnetx_032',\n",
              " 'regnetx_040',\n",
              " 'regnetx_064',\n",
              " 'regnetx_080',\n",
              " 'regnetx_120',\n",
              " 'regnetx_160',\n",
              " 'regnetx_320',\n",
              " 'regnety_002',\n",
              " 'regnety_004',\n",
              " 'regnety_006',\n",
              " 'regnety_008',\n",
              " 'regnety_008_tv',\n",
              " 'regnety_016',\n",
              " 'regnety_032',\n",
              " 'regnety_040',\n",
              " 'regnety_040_sgn',\n",
              " 'regnety_064',\n",
              " 'regnety_080',\n",
              " 'regnety_080_tv',\n",
              " 'regnety_120',\n",
              " 'regnety_160',\n",
              " 'regnety_320',\n",
              " 'regnety_640',\n",
              " 'regnety_1280',\n",
              " 'regnety_2560',\n",
              " 'regnetz_005',\n",
              " 'regnetz_040',\n",
              " 'regnetz_040_h',\n",
              " 'regnetz_b16',\n",
              " 'regnetz_b16_evos',\n",
              " 'regnetz_c16',\n",
              " 'regnetz_c16_evos',\n",
              " 'regnetz_d8',\n",
              " 'regnetz_d8_evos',\n",
              " 'regnetz_d32',\n",
              " 'regnetz_e8',\n",
              " 'repghostnet_050',\n",
              " 'repghostnet_058',\n",
              " 'repghostnet_080',\n",
              " 'repghostnet_100',\n",
              " 'repghostnet_111',\n",
              " 'repghostnet_130',\n",
              " 'repghostnet_150',\n",
              " 'repghostnet_200',\n",
              " 'repvgg_a0',\n",
              " 'repvgg_a1',\n",
              " 'repvgg_a2',\n",
              " 'repvgg_b0',\n",
              " 'repvgg_b1',\n",
              " 'repvgg_b1g4',\n",
              " 'repvgg_b2',\n",
              " 'repvgg_b2g4',\n",
              " 'repvgg_b3',\n",
              " 'repvgg_b3g4',\n",
              " 'repvgg_d2se',\n",
              " 'repvit_m0_9',\n",
              " 'repvit_m1',\n",
              " 'repvit_m1_0',\n",
              " 'repvit_m1_1',\n",
              " 'repvit_m1_5',\n",
              " 'repvit_m2',\n",
              " 'repvit_m2_3',\n",
              " 'repvit_m3',\n",
              " 'res2net50_14w_8s',\n",
              " 'res2net50_26w_4s',\n",
              " 'res2net50_26w_6s',\n",
              " 'res2net50_26w_8s',\n",
              " 'res2net50_48w_2s',\n",
              " 'res2net50d',\n",
              " 'res2net101_26w_4s',\n",
              " 'res2net101d',\n",
              " 'res2next50',\n",
              " 'resmlp_12_224',\n",
              " 'resmlp_24_224',\n",
              " 'resmlp_36_224',\n",
              " 'resmlp_big_24_224',\n",
              " 'resnest14d',\n",
              " 'resnest26d',\n",
              " 'resnest50d',\n",
              " 'resnest50d_1s4x24d',\n",
              " 'resnest50d_4s2x40d',\n",
              " 'resnest101e',\n",
              " 'resnest200e',\n",
              " 'resnest269e',\n",
              " 'resnet10t',\n",
              " 'resnet14t',\n",
              " 'resnet18',\n",
              " 'resnet18d',\n",
              " 'resnet26',\n",
              " 'resnet26d',\n",
              " 'resnet26t',\n",
              " 'resnet32ts',\n",
              " 'resnet33ts',\n",
              " 'resnet34',\n",
              " 'resnet34d',\n",
              " 'resnet50',\n",
              " 'resnet50_clip',\n",
              " 'resnet50_clip_gap',\n",
              " 'resnet50_gn',\n",
              " 'resnet50_mlp',\n",
              " 'resnet50c',\n",
              " 'resnet50d',\n",
              " 'resnet50s',\n",
              " 'resnet50t',\n",
              " 'resnet50x4_clip',\n",
              " 'resnet50x4_clip_gap',\n",
              " 'resnet50x16_clip',\n",
              " 'resnet50x16_clip_gap',\n",
              " 'resnet50x64_clip',\n",
              " 'resnet50x64_clip_gap',\n",
              " 'resnet51q',\n",
              " 'resnet61q',\n",
              " 'resnet101',\n",
              " 'resnet101_clip',\n",
              " 'resnet101_clip_gap',\n",
              " 'resnet101c',\n",
              " 'resnet101d',\n",
              " 'resnet101s',\n",
              " 'resnet152',\n",
              " 'resnet152c',\n",
              " 'resnet152d',\n",
              " 'resnet152s',\n",
              " 'resnet200',\n",
              " 'resnet200d',\n",
              " 'resnetaa34d',\n",
              " 'resnetaa50',\n",
              " 'resnetaa50d',\n",
              " 'resnetaa101d',\n",
              " 'resnetblur18',\n",
              " 'resnetblur50',\n",
              " 'resnetblur50d',\n",
              " 'resnetblur101d',\n",
              " 'resnetrs50',\n",
              " 'resnetrs101',\n",
              " 'resnetrs152',\n",
              " 'resnetrs200',\n",
              " 'resnetrs270',\n",
              " 'resnetrs350',\n",
              " 'resnetrs420',\n",
              " 'resnetv2_18',\n",
              " 'resnetv2_18d',\n",
              " 'resnetv2_34',\n",
              " 'resnetv2_34d',\n",
              " 'resnetv2_50',\n",
              " 'resnetv2_50d',\n",
              " 'resnetv2_50d_evos',\n",
              " 'resnetv2_50d_frn',\n",
              " 'resnetv2_50d_gn',\n",
              " 'resnetv2_50t',\n",
              " 'resnetv2_50x1_bit',\n",
              " 'resnetv2_50x3_bit',\n",
              " 'resnetv2_101',\n",
              " 'resnetv2_101d',\n",
              " 'resnetv2_101x1_bit',\n",
              " 'resnetv2_101x3_bit',\n",
              " 'resnetv2_152',\n",
              " 'resnetv2_152d',\n",
              " 'resnetv2_152x2_bit',\n",
              " 'resnetv2_152x4_bit',\n",
              " 'resnext26ts',\n",
              " 'resnext50_32x4d',\n",
              " 'resnext50d_32x4d',\n",
              " 'resnext101_32x4d',\n",
              " 'resnext101_32x8d',\n",
              " 'resnext101_32x16d',\n",
              " 'resnext101_32x32d',\n",
              " 'resnext101_64x4d',\n",
              " 'rexnet_100',\n",
              " 'rexnet_130',\n",
              " 'rexnet_150',\n",
              " 'rexnet_200',\n",
              " 'rexnet_300',\n",
              " 'rexnetr_100',\n",
              " 'rexnetr_130',\n",
              " 'rexnetr_150',\n",
              " 'rexnetr_200',\n",
              " 'rexnetr_300',\n",
              " 'sam2_hiera_base_plus',\n",
              " 'sam2_hiera_large',\n",
              " 'sam2_hiera_small',\n",
              " 'sam2_hiera_tiny',\n",
              " 'samvit_base_patch16',\n",
              " 'samvit_base_patch16_224',\n",
              " 'samvit_huge_patch16',\n",
              " 'samvit_large_patch16',\n",
              " 'sebotnet33ts_256',\n",
              " 'sedarknet21',\n",
              " 'sehalonet33ts',\n",
              " 'selecsls42',\n",
              " 'selecsls42b',\n",
              " 'selecsls60',\n",
              " 'selecsls60b',\n",
              " 'selecsls84',\n",
              " 'semnasnet_050',\n",
              " 'semnasnet_075',\n",
              " 'semnasnet_100',\n",
              " 'semnasnet_140',\n",
              " 'senet154',\n",
              " 'sequencer2d_l',\n",
              " 'sequencer2d_m',\n",
              " 'sequencer2d_s',\n",
              " 'seresnet18',\n",
              " 'seresnet33ts',\n",
              " 'seresnet34',\n",
              " 'seresnet50',\n",
              " 'seresnet50t',\n",
              " 'seresnet101',\n",
              " 'seresnet152',\n",
              " 'seresnet152d',\n",
              " 'seresnet200d',\n",
              " 'seresnet269d',\n",
              " 'seresnetaa50d',\n",
              " 'seresnext26d_32x4d',\n",
              " 'seresnext26t_32x4d',\n",
              " 'seresnext26ts',\n",
              " 'seresnext50_32x4d',\n",
              " 'seresnext101_32x4d',\n",
              " 'seresnext101_32x8d',\n",
              " 'seresnext101_64x4d',\n",
              " 'seresnext101d_32x8d',\n",
              " 'seresnextaa101d_32x8d',\n",
              " 'seresnextaa201d_32x8d',\n",
              " 'skresnet18',\n",
              " 'skresnet34',\n",
              " 'skresnet50',\n",
              " 'skresnet50d',\n",
              " 'skresnext50_32x4d',\n",
              " 'spnasnet_100',\n",
              " 'swin_base_patch4_window7_224',\n",
              " 'swin_base_patch4_window12_384',\n",
              " 'swin_large_patch4_window7_224',\n",
              " 'swin_large_patch4_window12_384',\n",
              " 'swin_s3_base_224',\n",
              " 'swin_s3_small_224',\n",
              " 'swin_s3_tiny_224',\n",
              " 'swin_small_patch4_window7_224',\n",
              " 'swin_tiny_patch4_window7_224',\n",
              " 'swinv2_base_window8_256',\n",
              " 'swinv2_base_window12_192',\n",
              " 'swinv2_base_window12to16_192to256',\n",
              " 'swinv2_base_window12to24_192to384',\n",
              " 'swinv2_base_window16_256',\n",
              " 'swinv2_cr_base_224',\n",
              " 'swinv2_cr_base_384',\n",
              " 'swinv2_cr_base_ns_224',\n",
              " 'swinv2_cr_giant_224',\n",
              " 'swinv2_cr_giant_384',\n",
              " 'swinv2_cr_huge_224',\n",
              " 'swinv2_cr_huge_384',\n",
              " 'swinv2_cr_large_224',\n",
              " 'swinv2_cr_large_384',\n",
              " 'swinv2_cr_small_224',\n",
              " 'swinv2_cr_small_384',\n",
              " 'swinv2_cr_small_ns_224',\n",
              " 'swinv2_cr_small_ns_256',\n",
              " 'swinv2_cr_tiny_224',\n",
              " 'swinv2_cr_tiny_384',\n",
              " 'swinv2_cr_tiny_ns_224',\n",
              " 'swinv2_large_window12_192',\n",
              " 'swinv2_large_window12to16_192to256',\n",
              " 'swinv2_large_window12to24_192to384',\n",
              " 'swinv2_small_window8_256',\n",
              " 'swinv2_small_window16_256',\n",
              " 'swinv2_tiny_window8_256',\n",
              " 'swinv2_tiny_window16_256',\n",
              " 'test_byobnet',\n",
              " 'test_convnext',\n",
              " 'test_convnext2',\n",
              " 'test_convnext3',\n",
              " 'test_efficientnet',\n",
              " 'test_efficientnet_evos',\n",
              " 'test_efficientnet_gn',\n",
              " 'test_efficientnet_ln',\n",
              " 'test_mambaout',\n",
              " 'test_nfnet',\n",
              " 'test_resnet',\n",
              " 'test_vit',\n",
              " 'test_vit2',\n",
              " 'test_vit3',\n",
              " 'tf_efficientnet_b0',\n",
              " 'tf_efficientnet_b1',\n",
              " 'tf_efficientnet_b2',\n",
              " 'tf_efficientnet_b3',\n",
              " 'tf_efficientnet_b4',\n",
              " 'tf_efficientnet_b5',\n",
              " 'tf_efficientnet_b6',\n",
              " 'tf_efficientnet_b7',\n",
              " 'tf_efficientnet_b8',\n",
              " 'tf_efficientnet_cc_b0_4e',\n",
              " 'tf_efficientnet_cc_b0_8e',\n",
              " 'tf_efficientnet_cc_b1_8e',\n",
              " 'tf_efficientnet_el',\n",
              " 'tf_efficientnet_em',\n",
              " 'tf_efficientnet_es',\n",
              " 'tf_efficientnet_l2',\n",
              " 'tf_efficientnet_lite0',\n",
              " 'tf_efficientnet_lite1',\n",
              " 'tf_efficientnet_lite2',\n",
              " 'tf_efficientnet_lite3',\n",
              " 'tf_efficientnet_lite4',\n",
              " 'tf_efficientnetv2_b0',\n",
              " 'tf_efficientnetv2_b1',\n",
              " 'tf_efficientnetv2_b2',\n",
              " 'tf_efficientnetv2_b3',\n",
              " 'tf_efficientnetv2_l',\n",
              " 'tf_efficientnetv2_m',\n",
              " 'tf_efficientnetv2_s',\n",
              " 'tf_efficientnetv2_xl',\n",
              " 'tf_mixnet_l',\n",
              " 'tf_mixnet_m',\n",
              " 'tf_mixnet_s',\n",
              " 'tf_mobilenetv3_large_075',\n",
              " 'tf_mobilenetv3_large_100',\n",
              " 'tf_mobilenetv3_large_minimal_100',\n",
              " 'tf_mobilenetv3_small_075',\n",
              " 'tf_mobilenetv3_small_100',\n",
              " 'tf_mobilenetv3_small_minimal_100',\n",
              " 'tiny_vit_5m_224',\n",
              " 'tiny_vit_11m_224',\n",
              " 'tiny_vit_21m_224',\n",
              " 'tiny_vit_21m_384',\n",
              " 'tiny_vit_21m_512',\n",
              " 'tinynet_a',\n",
              " 'tinynet_b',\n",
              " 'tinynet_c',\n",
              " 'tinynet_d',\n",
              " 'tinynet_e',\n",
              " 'tnt_b_patch16_224',\n",
              " 'tnt_s_patch16_224',\n",
              " 'tresnet_l',\n",
              " 'tresnet_m',\n",
              " 'tresnet_v2_l',\n",
              " 'tresnet_xl',\n",
              " 'twins_pcpvt_base',\n",
              " 'twins_pcpvt_large',\n",
              " 'twins_pcpvt_small',\n",
              " 'twins_svt_base',\n",
              " 'twins_svt_large',\n",
              " 'twins_svt_small',\n",
              " 'vgg11',\n",
              " 'vgg11_bn',\n",
              " 'vgg13',\n",
              " 'vgg13_bn',\n",
              " 'vgg16',\n",
              " 'vgg16_bn',\n",
              " 'vgg19',\n",
              " 'vgg19_bn',\n",
              " 'visformer_small',\n",
              " 'visformer_tiny',\n",
              " 'vit_base_mci_224',\n",
              " 'vit_base_patch8_224',\n",
              " 'vit_base_patch14_dinov2',\n",
              " 'vit_base_patch14_reg4_dinov2',\n",
              " 'vit_base_patch16_18x2_224',\n",
              " 'vit_base_patch16_224',\n",
              " 'vit_base_patch16_224_miil',\n",
              " 'vit_base_patch16_384',\n",
              " 'vit_base_patch16_clip_224',\n",
              " 'vit_base_patch16_clip_384',\n",
              " 'vit_base_patch16_clip_quickgelu_224',\n",
              " 'vit_base_patch16_gap_224',\n",
              " 'vit_base_patch16_plus_240',\n",
              " 'vit_base_patch16_reg4_gap_256',\n",
              " 'vit_base_patch16_rope_reg1_gap_256',\n",
              " 'vit_base_patch16_rpn_224',\n",
              " 'vit_base_patch16_siglip_224',\n",
              " 'vit_base_patch16_siglip_256',\n",
              " 'vit_base_patch16_siglip_384',\n",
              " 'vit_base_patch16_siglip_512',\n",
              " 'vit_base_patch16_siglip_gap_224',\n",
              " 'vit_base_patch16_siglip_gap_256',\n",
              " 'vit_base_patch16_siglip_gap_384',\n",
              " 'vit_base_patch16_siglip_gap_512',\n",
              " 'vit_base_patch16_xp_224',\n",
              " 'vit_base_patch32_224',\n",
              " 'vit_base_patch32_384',\n",
              " 'vit_base_patch32_clip_224',\n",
              " 'vit_base_patch32_clip_256',\n",
              " 'vit_base_patch32_clip_384',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "timm.list_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBDfA1APGi5y"
      },
      "source": [
        "We will train a ResNet-18 that is already pre-trained on ImageNet.\n",
        "You can read more about ResNet in this [paper](https://arxiv.org/abs/1512.03385).\n",
        "\n",
        "<img src=https://www.researchgate.net/publication/366608244/figure/fig1/AS:11431281109643320@1672145338540/Structure-of-the-Resnet-18-Model.jpg>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZA0MnrJInTx0",
        "outputId": "e12d6126-ad0b-46df-8771-27f9fd3f3594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (act1): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "Number of parameters: 11689512\n"
          ]
        }
      ],
      "source": [
        "resnet = timm.create_model('resnet18', pretrained=True)\n",
        "print(resnet)\n",
        "print(\"Number of parameters:\", count_parameters(resnet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc5Wy-UsnlFG"
      },
      "source": [
        "Similarly, we will need to modify the classifier to have only 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DzIpaqLqnq3w",
        "outputId": "47eb1831-ef4d-423f-caf2-bd1c3748c609",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (act1): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (drop_block): Identity()\n",
            "      (act1): ReLU(inplace=True)\n",
            "      (aa): Identity()\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "Number of parameters: 11181642\n"
          ]
        }
      ],
      "source": [
        "resnet.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "resnet.to(device)\n",
        "print(resnet)\n",
        "print(\"Number of parameters:\", count_parameters(resnet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cxQ2Oor629Q"
      },
      "source": [
        "We run the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dttn92Gzn3jo",
        "outputId": "6da5c792-5e3c-4941-ea91-51a6b2b94213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 38%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–Š      \u001b[0m| 74/196 [03:12<05:17,  2.60s/it, Epoch=0, Train_Loss=1.95]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-05c83e641360>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You may have to play with the hyperparameters to obtain better results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-417fcf9f7dcc>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# For validation we do not keep track of gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-912af7791e15>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, device, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Obtain predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Compute loss for this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/resnet.py\u001b[0m in \u001b[0;36mforward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/timm/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# You may have to play with the hyperparameters to obtain better results\n",
        "run_training(model=resnet, num_epochs=10, learning_rate=0.0005)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNet from HuggingFace"
      ],
      "metadata": {
        "id": "qgouVJX6j10_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMOfmvbQIMSs"
      },
      "source": [
        "Finally, we will use a model from the Hugging Face library."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the MobileNet architecture. You can read more about it in this [paper](https://arxiv.org/abs/1704.04861)"
      ],
      "metadata": {
        "id": "qM7l7K-19L3q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RpAZ-2P_o2XX",
        "outputId": "3ae2ce8d-2a72-40fe-df7e-c04e38d53a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "e10a7834e18a47c0b5350514dbefc141",
            "425a70fc7920470286e2d7fc5b3785b2",
            "9d52468c909148f798b964eff21286ce",
            "7f9c82873cfe48bcaaa5e5d895ba41f7",
            "8ae824e522c243eca9262b55fd1096d9",
            "53f2203e0e264920a574872ac92e1d90",
            "3dffa4dc724e43c6a92790dc81dc3280",
            "7a3ad1f038ab4619bab48bd20344be25",
            "9c57ca9368a44e3d9370805903a73c06",
            "2205b3eee1364992853cc504b6235fd0",
            "93a639642be84e26a4f40f259a7287a7"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e10a7834e18a47c0b5350514dbefc141"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForImageClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2mFNcC1JU-s"
      },
      "source": [
        "We utilize `AutoModelForImageClassification.from_pretrained`to create the model.\n",
        "As in the other cases, we change the classifier to have only 10 classes.\n",
        "\n",
        "We build a wrapper around the model to only output the score for each class (by default it also outputs the loss). We only do this so it works with our train and valid functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vnNHsyn7o5cz",
        "outputId": "abe88560-c31d-4cb8-bbf4-7c1ce010f892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cd330158b9d44f6b9c0ec39608c9fd9c",
            "52aae5dd9285401082a03657336b04e8",
            "2a337064e486466e8e32d449d5b8fb20",
            "9c801b9ff2f94a47b18a03ab8ebac783",
            "673b8443090d4f8194e56cf8eb77abc5",
            "4c51ade297134e929da8ff9bc26d2de9",
            "ea45b3c0a27544fb881010cc342ec116",
            "0cd6e523bd4c4fa99e7419f4e4525121",
            "dceaa0a0f2f147fb8028454f0b8ab8f0",
            "fdc3d6432cb442b183c27fa62f837d58",
            "1fa6152a29884e289c8bac92cf9fd117",
            "35827a48d993484d9382ce3cc829184b",
            "bf71a854f6804180a4fff128d7307fdc",
            "d4a1920424b8491a99bee054ce861a18",
            "bd73cf7a0283452baad04c0241c63347",
            "b1b92c32af824951aeb06232e5c3bfe6",
            "7f309973c5624acbbfa497ab700d6b83",
            "dc82f3c833654770a0bf91aafa54f3c9",
            "4dd93c08d42742cdaf125be57fb78a3f",
            "9e8110572e994eebb9a758c150efda94",
            "b251b69bd4c7460384292a8b658ceab1",
            "f653803ed3544d6bb2462bab3249e4ed"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/69.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd330158b9d44f6b9c0ec39608c9fd9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35827a48d993484d9382ce3cc829184b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 2236682\n",
            "MobileNetWrapper(\n",
            "  (model): MobileNetV2ForImageClassification(\n",
            "    (mobilenet_v2): MobileNetV2Model(\n",
            "      (conv_stem): MobileNetV2Stem(\n",
            "        (first_conv): MobileNetV2ConvLayer(\n",
            "          (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU6()\n",
            "        )\n",
            "        (conv_3x3): MobileNetV2ConvLayer(\n",
            "          (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False)\n",
            "          (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU6()\n",
            "        )\n",
            "        (reduce_1x1): MobileNetV2ConvLayer(\n",
            "          (convolution): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (normalization): BatchNorm2d(16, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (layer): ModuleList(\n",
            "        (0): MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
            "            (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False)\n",
            "            (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(24, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (2): MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), groups=144, bias=False)\n",
            "            (normalization): BatchNorm2d(144, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (3-4): 2 x MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False)\n",
            "            (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(32, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (5): MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
            "            (normalization): BatchNorm2d(192, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (6-8): 3 x MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
            "            (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(64, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (9): MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), groups=384, bias=False)\n",
            "            (normalization): BatchNorm2d(384, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (10-11): 2 x MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False)\n",
            "            (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(96, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (12): MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), groups=576, bias=False)\n",
            "            (normalization): BatchNorm2d(576, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (13-14): 2 x MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
            "            (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(160, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (15): MobileNetV2InvertedResidual(\n",
            "          (expand_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (conv_3x3): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False)\n",
            "            (normalization): BatchNorm2d(960, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "            (activation): ReLU6()\n",
            "          )\n",
            "          (reduce_1x1): MobileNetV2ConvLayer(\n",
            "            (convolution): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (normalization): BatchNorm2d(320, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (conv_1x1): MobileNetV2ConvLayer(\n",
            "        (convolution): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (normalization): BatchNorm2d(1280, eps=0.001, momentum=0.997, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU6()\n",
            "      )\n",
            "      (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    )\n",
            "    (dropout): Dropout(p=0.2, inplace=True)\n",
            "    (classifier): Linear(in_features=1280, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class MobileNetWrapper(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MobileNetWrapper, self).__init__()\n",
        "    self.model = AutoModelForImageClassification.from_pretrained(\"google/mobilenet_v2_1.0_224\")\n",
        "\n",
        "    # Changing the classifier to output only 10 classes\n",
        "    self.model.classifier = nn.Linear(in_features=1280, out_features=10, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x).logits\n",
        "\n",
        "mobilenet = MobileNetWrapper()\n",
        "mobilenet.to(device)\n",
        "print(\"Number of parameters:\", count_parameters(mobilenet))\n",
        "print(mobilenet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9ksgfJ5Apib5",
        "outputId": "10a34de1-aa1d-45e8-c658-011d7a8adcab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 35%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–      \u001b[0m| 68/196 [01:49<03:26,  1.61s/it, Epoch=0, Train_Loss=1.58]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-95a5c7d80f46>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You may have to play with the hyperparameters to obtain better results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmobilenet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-417fcf9f7dcc>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# For validation we do not keep track of gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-912af7791e15>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, device, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Compute gradients for each weight (backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Update weights based on gradients (gradient descent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# You may have to play with the hyperparameters to obtain better results\n",
        "run_training(model=mobilenet, num_epochs=10, learning_rate=0.0005)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Vba_tdL161"
      },
      "source": [
        "### Training only a subset of layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSJyPLsvMrRm"
      },
      "source": [
        "When using pre-trained models that were trained on similar images, we do not have to re-train every layer of the network.\n",
        "\n",
        "Ideally the first layers of the network already extract meaningful features which can be utilized in our task. So, in theory we don't have to re-train these first layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idIVzmyM629R"
      },
      "source": [
        "We will demonstrate this by fine-tuning only a part of the resnet-18 model. Let's have a closer look at the structure of ResNet18."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EOmFCDqT629R",
        "outputId": "2a2588d6-8b9d-472d-d35f-43b27a12a9a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (act1): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (drop_block): Identity()\n",
              "      (act1): ReLU(inplace=True)\n",
              "      (aa): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (act2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "resnet = timm.create_model('resnet18', pretrained=True)\n",
        "\n",
        "# Change the output layer to match the number of classes in CIFAR-10\n",
        "resnet.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "\n",
        "resnet.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83L2CxEN629R"
      },
      "source": [
        "<img src=https://www.researchgate.net/publication/366608244/figure/fig1/AS:11431281109643320@1672145338540/Structure-of-the-Resnet-18-Model.jpg>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClWOi53l629R"
      },
      "source": [
        "The model has an initial 7x7 Conv, followed by a Pooling Layer.\n",
        "\n",
        "Afterwards, it has 4 layers, each with the same structure. Finally, it has a fully connected classifier (which we changed to output only 10 scores instead of 1000).\n",
        "\n",
        "A layer is composed of 2 Building Blocks. A building Block contains the following:\n",
        "1. A 3x3 Conv\n",
        "2. Batch Norm - read more about this operation [here](https://arxiv.org/abs/1502.03167)\n",
        "3. Activation - ReLU\n",
        "4. A second 3x3 Conv\n",
        "5. Batch Norm\n",
        "6. Activation - ReLU\n",
        "7. Residual Connection with the Input - input + output - read more about this [here](https://arxiv.org/abs/1512.03385)\n",
        "\n",
        "A Building Block with residual connection looks like this:\n",
        "\n",
        "<img src=https://miro.medium.com/v2/resize:fit:570/1*D0F3UitQ2l5Q0Ak-tjEdJg.png width=300px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8e_vFtR629R"
      },
      "source": [
        "We will start by freezing all the parameters of the model. This means that we tell pytorch not to compute gradients for these parameters.\n",
        "\n",
        "Any parameter that is frozen will not be changed during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LsxVUSkW629R"
      },
      "outputs": [],
      "source": [
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKjMRxMc629R"
      },
      "source": [
        "Function that prints the name of the parameter and if it's trainable or frozen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nyGVlGrO629R"
      },
      "outputs": [],
      "source": [
        "def print_params(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mzGdxUzb629R",
        "collapsed": true,
        "outputId": "cc9f4b98-7000-4dd6-a779-3dfb39bfaee8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight False\n",
            "bn1.weight False\n",
            "bn1.bias False\n",
            "layer1.0.conv1.weight False\n",
            "layer1.0.bn1.weight False\n",
            "layer1.0.bn1.bias False\n",
            "layer1.0.conv2.weight False\n",
            "layer1.0.bn2.weight False\n",
            "layer1.0.bn2.bias False\n",
            "layer1.1.conv1.weight False\n",
            "layer1.1.bn1.weight False\n",
            "layer1.1.bn1.bias False\n",
            "layer1.1.conv2.weight False\n",
            "layer1.1.bn2.weight False\n",
            "layer1.1.bn2.bias False\n",
            "layer2.0.conv1.weight False\n",
            "layer2.0.bn1.weight False\n",
            "layer2.0.bn1.bias False\n",
            "layer2.0.conv2.weight False\n",
            "layer2.0.bn2.weight False\n",
            "layer2.0.bn2.bias False\n",
            "layer2.0.downsample.0.weight False\n",
            "layer2.0.downsample.1.weight False\n",
            "layer2.0.downsample.1.bias False\n",
            "layer2.1.conv1.weight False\n",
            "layer2.1.bn1.weight False\n",
            "layer2.1.bn1.bias False\n",
            "layer2.1.conv2.weight False\n",
            "layer2.1.bn2.weight False\n",
            "layer2.1.bn2.bias False\n",
            "layer3.0.conv1.weight False\n",
            "layer3.0.bn1.weight False\n",
            "layer3.0.bn1.bias False\n",
            "layer3.0.conv2.weight False\n",
            "layer3.0.bn2.weight False\n",
            "layer3.0.bn2.bias False\n",
            "layer3.0.downsample.0.weight False\n",
            "layer3.0.downsample.1.weight False\n",
            "layer3.0.downsample.1.bias False\n",
            "layer3.1.conv1.weight False\n",
            "layer3.1.bn1.weight False\n",
            "layer3.1.bn1.bias False\n",
            "layer3.1.conv2.weight False\n",
            "layer3.1.bn2.weight False\n",
            "layer3.1.bn2.bias False\n",
            "layer4.0.conv1.weight False\n",
            "layer4.0.bn1.weight False\n",
            "layer4.0.bn1.bias False\n",
            "layer4.0.conv2.weight False\n",
            "layer4.0.bn2.weight False\n",
            "layer4.0.bn2.bias False\n",
            "layer4.0.downsample.0.weight False\n",
            "layer4.0.downsample.1.weight False\n",
            "layer4.0.downsample.1.bias False\n",
            "layer4.1.conv1.weight False\n",
            "layer4.1.bn1.weight False\n",
            "layer4.1.bn1.bias False\n",
            "layer4.1.conv2.weight False\n",
            "layer4.1.bn2.weight False\n",
            "layer4.1.bn2.bias False\n",
            "fc.weight False\n",
            "fc.bias False\n"
          ]
        }
      ],
      "source": [
        "print_params(resnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HesC9Gmm629R"
      },
      "source": [
        "All the parameters of the model are frozen.\n",
        "\n",
        "We will unfreeze only the final fc layer.\n",
        "\n",
        "We usually freeze the first layers and fine-tune the later ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RBxy6aRW629R",
        "outputId": "175552da-a8da-4978-974b-0d4f538e73d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight False\n",
            "bn1.weight False\n",
            "bn1.bias False\n",
            "layer1.0.conv1.weight False\n",
            "layer1.0.bn1.weight False\n",
            "layer1.0.bn1.bias False\n",
            "layer1.0.conv2.weight False\n",
            "layer1.0.bn2.weight False\n",
            "layer1.0.bn2.bias False\n",
            "layer1.1.conv1.weight False\n",
            "layer1.1.bn1.weight False\n",
            "layer1.1.bn1.bias False\n",
            "layer1.1.conv2.weight False\n",
            "layer1.1.bn2.weight False\n",
            "layer1.1.bn2.bias False\n",
            "layer2.0.conv1.weight False\n",
            "layer2.0.bn1.weight False\n",
            "layer2.0.bn1.bias False\n",
            "layer2.0.conv2.weight False\n",
            "layer2.0.bn2.weight False\n",
            "layer2.0.bn2.bias False\n",
            "layer2.0.downsample.0.weight False\n",
            "layer2.0.downsample.1.weight False\n",
            "layer2.0.downsample.1.bias False\n",
            "layer2.1.conv1.weight False\n",
            "layer2.1.bn1.weight False\n",
            "layer2.1.bn1.bias False\n",
            "layer2.1.conv2.weight False\n",
            "layer2.1.bn2.weight False\n",
            "layer2.1.bn2.bias False\n",
            "layer3.0.conv1.weight False\n",
            "layer3.0.bn1.weight False\n",
            "layer3.0.bn1.bias False\n",
            "layer3.0.conv2.weight False\n",
            "layer3.0.bn2.weight False\n",
            "layer3.0.bn2.bias False\n",
            "layer3.0.downsample.0.weight False\n",
            "layer3.0.downsample.1.weight False\n",
            "layer3.0.downsample.1.bias False\n",
            "layer3.1.conv1.weight False\n",
            "layer3.1.bn1.weight False\n",
            "layer3.1.bn1.bias False\n",
            "layer3.1.conv2.weight False\n",
            "layer3.1.bn2.weight False\n",
            "layer3.1.bn2.bias False\n",
            "layer4.0.conv1.weight False\n",
            "layer4.0.bn1.weight False\n",
            "layer4.0.bn1.bias False\n",
            "layer4.0.conv2.weight False\n",
            "layer4.0.bn2.weight False\n",
            "layer4.0.bn2.bias False\n",
            "layer4.0.downsample.0.weight False\n",
            "layer4.0.downsample.1.weight False\n",
            "layer4.0.downsample.1.bias False\n",
            "layer4.1.conv1.weight False\n",
            "layer4.1.bn1.weight False\n",
            "layer4.1.bn1.bias False\n",
            "layer4.1.conv2.weight False\n",
            "layer4.1.bn2.weight False\n",
            "layer4.1.bn2.bias False\n",
            "fc.weight True\n",
            "fc.bias True\n",
            "Number of trainable parameters: 5130\n"
          ]
        }
      ],
      "source": [
        "for param in resnet.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print_params(resnet)\n",
        "print(\"Number of trainable parameters:\", count_parameters(resnet))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6q7jTbV629S"
      },
      "source": [
        "Notice that we only have 5130 trainable parameters out of 11M.\n",
        "Let's run the training and see if the model learns anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QOHbxniK629S",
        "outputId": "963afc3e-7b79-4ad8-e029-a5d645a07897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla T4\n",
            "\n",
            " 10%|\u001b[36mâ–‰         \u001b[0m| 19/196 [00:03<00:28,  6.24it/s, Epoch=0, Train_Loss=2.33]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1893bb104563>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You may have to play with the hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-417fcf9f7dcc>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(model, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# For validation we do not keep track of gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-912af7791e15>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, device, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# We keep track of the average training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mdataset_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# You may have to play with the hyperparameters\n",
        "run_training(model=resnet, num_epochs=20, learning_rate=0.0003)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-h3D3Kc629S"
      },
      "source": [
        "**Exercise 1** - Unfreeze all the BatchNorm (bn) weights and biases and re-train the network. See what you observe.\n",
        "\n",
        "- Play with freezing and unfreezing certain parts of the network. See if you can obtain good results without having to re-train too many parameters."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in resnet.named_parameters():\n",
        "  if 'bn' in name:\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"Number of trainable parameters:\", count_parameters(resnet))"
      ],
      "metadata": {
        "id": "CJ8NVrD7tI-W",
        "outputId": "3374eb54-e014-400d-d40f-eff8a9754f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters: 12938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7A6ySYm629S"
      },
      "source": [
        "**Exercise 2** - Try to obtain the highest accuracy possible on CIFAR-10.\n",
        "- Use any model you want from any of the presented libraries\n",
        "- Use image augmentations in training and try to find optimal hyperparameters\n",
        "- Models trained on ImageNet were trained with 224x224 images. What happens if you resize the CIFAR-10 32x32 images to the 224x224 size? (Training will take a very long time if you do this, but try it for 1-2 epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    transforms.Resize((224, 224))\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "\n",
        "# The batch size is the number of images the model processes in parallel\n",
        "# We use shuffle for training as we don't want the model to see the images in the same order\n",
        "trainloader = DataLoader(trainset, batch_size=256,shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "TNlqHnCFuavu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "densenet = timm.create_model('densenet121', pretrained=True)\n",
        "print(densenet)\n",
        "print(\"Number of parameters:\", count_parameters(densenet))"
      ],
      "metadata": {
        "id": "5_SnV5WqwZos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of features in the penultimate layer\n",
        "num_ftrs = densenet.classifier.in_features\n",
        "\n",
        "# Replace the classifier with a new Linear layer\n",
        "# with the correct output dimension (10 for CIFAR-10)\n",
        "densenet.classifier = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# Move the model to the device (GPU if available)\n",
        "densenet.to(device)"
      ],
      "metadata": {
        "id": "w6V2dhgVxKox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_params(densenet)"
      ],
      "metadata": {
        "id": "QtvnkeeRxotw",
        "outputId": "5fae96b3-73e0-4844-fc2b-2e0ad731880e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features.conv0.weight True\n",
            "features.norm0.weight True\n",
            "features.norm0.bias True\n",
            "features.denseblock1.denselayer1.norm1.weight True\n",
            "features.denseblock1.denselayer1.norm1.bias True\n",
            "features.denseblock1.denselayer1.conv1.weight True\n",
            "features.denseblock1.denselayer1.norm2.weight True\n",
            "features.denseblock1.denselayer1.norm2.bias True\n",
            "features.denseblock1.denselayer1.conv2.weight True\n",
            "features.denseblock1.denselayer2.norm1.weight True\n",
            "features.denseblock1.denselayer2.norm1.bias True\n",
            "features.denseblock1.denselayer2.conv1.weight True\n",
            "features.denseblock1.denselayer2.norm2.weight True\n",
            "features.denseblock1.denselayer2.norm2.bias True\n",
            "features.denseblock1.denselayer2.conv2.weight True\n",
            "features.denseblock1.denselayer3.norm1.weight True\n",
            "features.denseblock1.denselayer3.norm1.bias True\n",
            "features.denseblock1.denselayer3.conv1.weight True\n",
            "features.denseblock1.denselayer3.norm2.weight True\n",
            "features.denseblock1.denselayer3.norm2.bias True\n",
            "features.denseblock1.denselayer3.conv2.weight True\n",
            "features.denseblock1.denselayer4.norm1.weight True\n",
            "features.denseblock1.denselayer4.norm1.bias True\n",
            "features.denseblock1.denselayer4.conv1.weight True\n",
            "features.denseblock1.denselayer4.norm2.weight True\n",
            "features.denseblock1.denselayer4.norm2.bias True\n",
            "features.denseblock1.denselayer4.conv2.weight True\n",
            "features.denseblock1.denselayer5.norm1.weight True\n",
            "features.denseblock1.denselayer5.norm1.bias True\n",
            "features.denseblock1.denselayer5.conv1.weight True\n",
            "features.denseblock1.denselayer5.norm2.weight True\n",
            "features.denseblock1.denselayer5.norm2.bias True\n",
            "features.denseblock1.denselayer5.conv2.weight True\n",
            "features.denseblock1.denselayer6.norm1.weight True\n",
            "features.denseblock1.denselayer6.norm1.bias True\n",
            "features.denseblock1.denselayer6.conv1.weight True\n",
            "features.denseblock1.denselayer6.norm2.weight True\n",
            "features.denseblock1.denselayer6.norm2.bias True\n",
            "features.denseblock1.denselayer6.conv2.weight True\n",
            "features.transition1.norm.weight True\n",
            "features.transition1.norm.bias True\n",
            "features.transition1.conv.weight True\n",
            "features.denseblock2.denselayer1.norm1.weight True\n",
            "features.denseblock2.denselayer1.norm1.bias True\n",
            "features.denseblock2.denselayer1.conv1.weight True\n",
            "features.denseblock2.denselayer1.norm2.weight True\n",
            "features.denseblock2.denselayer1.norm2.bias True\n",
            "features.denseblock2.denselayer1.conv2.weight True\n",
            "features.denseblock2.denselayer2.norm1.weight True\n",
            "features.denseblock2.denselayer2.norm1.bias True\n",
            "features.denseblock2.denselayer2.conv1.weight True\n",
            "features.denseblock2.denselayer2.norm2.weight True\n",
            "features.denseblock2.denselayer2.norm2.bias True\n",
            "features.denseblock2.denselayer2.conv2.weight True\n",
            "features.denseblock2.denselayer3.norm1.weight True\n",
            "features.denseblock2.denselayer3.norm1.bias True\n",
            "features.denseblock2.denselayer3.conv1.weight True\n",
            "features.denseblock2.denselayer3.norm2.weight True\n",
            "features.denseblock2.denselayer3.norm2.bias True\n",
            "features.denseblock2.denselayer3.conv2.weight True\n",
            "features.denseblock2.denselayer4.norm1.weight True\n",
            "features.denseblock2.denselayer4.norm1.bias True\n",
            "features.denseblock2.denselayer4.conv1.weight True\n",
            "features.denseblock2.denselayer4.norm2.weight True\n",
            "features.denseblock2.denselayer4.norm2.bias True\n",
            "features.denseblock2.denselayer4.conv2.weight True\n",
            "features.denseblock2.denselayer5.norm1.weight True\n",
            "features.denseblock2.denselayer5.norm1.bias True\n",
            "features.denseblock2.denselayer5.conv1.weight True\n",
            "features.denseblock2.denselayer5.norm2.weight True\n",
            "features.denseblock2.denselayer5.norm2.bias True\n",
            "features.denseblock2.denselayer5.conv2.weight True\n",
            "features.denseblock2.denselayer6.norm1.weight True\n",
            "features.denseblock2.denselayer6.norm1.bias True\n",
            "features.denseblock2.denselayer6.conv1.weight True\n",
            "features.denseblock2.denselayer6.norm2.weight True\n",
            "features.denseblock2.denselayer6.norm2.bias True\n",
            "features.denseblock2.denselayer6.conv2.weight True\n",
            "features.denseblock2.denselayer7.norm1.weight True\n",
            "features.denseblock2.denselayer7.norm1.bias True\n",
            "features.denseblock2.denselayer7.conv1.weight True\n",
            "features.denseblock2.denselayer7.norm2.weight True\n",
            "features.denseblock2.denselayer7.norm2.bias True\n",
            "features.denseblock2.denselayer7.conv2.weight True\n",
            "features.denseblock2.denselayer8.norm1.weight True\n",
            "features.denseblock2.denselayer8.norm1.bias True\n",
            "features.denseblock2.denselayer8.conv1.weight True\n",
            "features.denseblock2.denselayer8.norm2.weight True\n",
            "features.denseblock2.denselayer8.norm2.bias True\n",
            "features.denseblock2.denselayer8.conv2.weight True\n",
            "features.denseblock2.denselayer9.norm1.weight True\n",
            "features.denseblock2.denselayer9.norm1.bias True\n",
            "features.denseblock2.denselayer9.conv1.weight True\n",
            "features.denseblock2.denselayer9.norm2.weight True\n",
            "features.denseblock2.denselayer9.norm2.bias True\n",
            "features.denseblock2.denselayer9.conv2.weight True\n",
            "features.denseblock2.denselayer10.norm1.weight True\n",
            "features.denseblock2.denselayer10.norm1.bias True\n",
            "features.denseblock2.denselayer10.conv1.weight True\n",
            "features.denseblock2.denselayer10.norm2.weight True\n",
            "features.denseblock2.denselayer10.norm2.bias True\n",
            "features.denseblock2.denselayer10.conv2.weight True\n",
            "features.denseblock2.denselayer11.norm1.weight True\n",
            "features.denseblock2.denselayer11.norm1.bias True\n",
            "features.denseblock2.denselayer11.conv1.weight True\n",
            "features.denseblock2.denselayer11.norm2.weight True\n",
            "features.denseblock2.denselayer11.norm2.bias True\n",
            "features.denseblock2.denselayer11.conv2.weight True\n",
            "features.denseblock2.denselayer12.norm1.weight True\n",
            "features.denseblock2.denselayer12.norm1.bias True\n",
            "features.denseblock2.denselayer12.conv1.weight True\n",
            "features.denseblock2.denselayer12.norm2.weight True\n",
            "features.denseblock2.denselayer12.norm2.bias True\n",
            "features.denseblock2.denselayer12.conv2.weight True\n",
            "features.transition2.norm.weight True\n",
            "features.transition2.norm.bias True\n",
            "features.transition2.conv.weight True\n",
            "features.denseblock3.denselayer1.norm1.weight True\n",
            "features.denseblock3.denselayer1.norm1.bias True\n",
            "features.denseblock3.denselayer1.conv1.weight True\n",
            "features.denseblock3.denselayer1.norm2.weight True\n",
            "features.denseblock3.denselayer1.norm2.bias True\n",
            "features.denseblock3.denselayer1.conv2.weight True\n",
            "features.denseblock3.denselayer2.norm1.weight True\n",
            "features.denseblock3.denselayer2.norm1.bias True\n",
            "features.denseblock3.denselayer2.conv1.weight True\n",
            "features.denseblock3.denselayer2.norm2.weight True\n",
            "features.denseblock3.denselayer2.norm2.bias True\n",
            "features.denseblock3.denselayer2.conv2.weight True\n",
            "features.denseblock3.denselayer3.norm1.weight True\n",
            "features.denseblock3.denselayer3.norm1.bias True\n",
            "features.denseblock3.denselayer3.conv1.weight True\n",
            "features.denseblock3.denselayer3.norm2.weight True\n",
            "features.denseblock3.denselayer3.norm2.bias True\n",
            "features.denseblock3.denselayer3.conv2.weight True\n",
            "features.denseblock3.denselayer4.norm1.weight True\n",
            "features.denseblock3.denselayer4.norm1.bias True\n",
            "features.denseblock3.denselayer4.conv1.weight True\n",
            "features.denseblock3.denselayer4.norm2.weight True\n",
            "features.denseblock3.denselayer4.norm2.bias True\n",
            "features.denseblock3.denselayer4.conv2.weight True\n",
            "features.denseblock3.denselayer5.norm1.weight True\n",
            "features.denseblock3.denselayer5.norm1.bias True\n",
            "features.denseblock3.denselayer5.conv1.weight True\n",
            "features.denseblock3.denselayer5.norm2.weight True\n",
            "features.denseblock3.denselayer5.norm2.bias True\n",
            "features.denseblock3.denselayer5.conv2.weight True\n",
            "features.denseblock3.denselayer6.norm1.weight True\n",
            "features.denseblock3.denselayer6.norm1.bias True\n",
            "features.denseblock3.denselayer6.conv1.weight True\n",
            "features.denseblock3.denselayer6.norm2.weight True\n",
            "features.denseblock3.denselayer6.norm2.bias True\n",
            "features.denseblock3.denselayer6.conv2.weight True\n",
            "features.denseblock3.denselayer7.norm1.weight True\n",
            "features.denseblock3.denselayer7.norm1.bias True\n",
            "features.denseblock3.denselayer7.conv1.weight True\n",
            "features.denseblock3.denselayer7.norm2.weight True\n",
            "features.denseblock3.denselayer7.norm2.bias True\n",
            "features.denseblock3.denselayer7.conv2.weight True\n",
            "features.denseblock3.denselayer8.norm1.weight True\n",
            "features.denseblock3.denselayer8.norm1.bias True\n",
            "features.denseblock3.denselayer8.conv1.weight True\n",
            "features.denseblock3.denselayer8.norm2.weight True\n",
            "features.denseblock3.denselayer8.norm2.bias True\n",
            "features.denseblock3.denselayer8.conv2.weight True\n",
            "features.denseblock3.denselayer9.norm1.weight True\n",
            "features.denseblock3.denselayer9.norm1.bias True\n",
            "features.denseblock3.denselayer9.conv1.weight True\n",
            "features.denseblock3.denselayer9.norm2.weight True\n",
            "features.denseblock3.denselayer9.norm2.bias True\n",
            "features.denseblock3.denselayer9.conv2.weight True\n",
            "features.denseblock3.denselayer10.norm1.weight True\n",
            "features.denseblock3.denselayer10.norm1.bias True\n",
            "features.denseblock3.denselayer10.conv1.weight True\n",
            "features.denseblock3.denselayer10.norm2.weight True\n",
            "features.denseblock3.denselayer10.norm2.bias True\n",
            "features.denseblock3.denselayer10.conv2.weight True\n",
            "features.denseblock3.denselayer11.norm1.weight True\n",
            "features.denseblock3.denselayer11.norm1.bias True\n",
            "features.denseblock3.denselayer11.conv1.weight True\n",
            "features.denseblock3.denselayer11.norm2.weight True\n",
            "features.denseblock3.denselayer11.norm2.bias True\n",
            "features.denseblock3.denselayer11.conv2.weight True\n",
            "features.denseblock3.denselayer12.norm1.weight True\n",
            "features.denseblock3.denselayer12.norm1.bias True\n",
            "features.denseblock3.denselayer12.conv1.weight True\n",
            "features.denseblock3.denselayer12.norm2.weight True\n",
            "features.denseblock3.denselayer12.norm2.bias True\n",
            "features.denseblock3.denselayer12.conv2.weight True\n",
            "features.denseblock3.denselayer13.norm1.weight True\n",
            "features.denseblock3.denselayer13.norm1.bias True\n",
            "features.denseblock3.denselayer13.conv1.weight True\n",
            "features.denseblock3.denselayer13.norm2.weight True\n",
            "features.denseblock3.denselayer13.norm2.bias True\n",
            "features.denseblock3.denselayer13.conv2.weight True\n",
            "features.denseblock3.denselayer14.norm1.weight True\n",
            "features.denseblock3.denselayer14.norm1.bias True\n",
            "features.denseblock3.denselayer14.conv1.weight True\n",
            "features.denseblock3.denselayer14.norm2.weight True\n",
            "features.denseblock3.denselayer14.norm2.bias True\n",
            "features.denseblock3.denselayer14.conv2.weight True\n",
            "features.denseblock3.denselayer15.norm1.weight True\n",
            "features.denseblock3.denselayer15.norm1.bias True\n",
            "features.denseblock3.denselayer15.conv1.weight True\n",
            "features.denseblock3.denselayer15.norm2.weight True\n",
            "features.denseblock3.denselayer15.norm2.bias True\n",
            "features.denseblock3.denselayer15.conv2.weight True\n",
            "features.denseblock3.denselayer16.norm1.weight True\n",
            "features.denseblock3.denselayer16.norm1.bias True\n",
            "features.denseblock3.denselayer16.conv1.weight True\n",
            "features.denseblock3.denselayer16.norm2.weight True\n",
            "features.denseblock3.denselayer16.norm2.bias True\n",
            "features.denseblock3.denselayer16.conv2.weight True\n",
            "features.denseblock3.denselayer17.norm1.weight True\n",
            "features.denseblock3.denselayer17.norm1.bias True\n",
            "features.denseblock3.denselayer17.conv1.weight True\n",
            "features.denseblock3.denselayer17.norm2.weight True\n",
            "features.denseblock3.denselayer17.norm2.bias True\n",
            "features.denseblock3.denselayer17.conv2.weight True\n",
            "features.denseblock3.denselayer18.norm1.weight True\n",
            "features.denseblock3.denselayer18.norm1.bias True\n",
            "features.denseblock3.denselayer18.conv1.weight True\n",
            "features.denseblock3.denselayer18.norm2.weight True\n",
            "features.denseblock3.denselayer18.norm2.bias True\n",
            "features.denseblock3.denselayer18.conv2.weight True\n",
            "features.denseblock3.denselayer19.norm1.weight True\n",
            "features.denseblock3.denselayer19.norm1.bias True\n",
            "features.denseblock3.denselayer19.conv1.weight True\n",
            "features.denseblock3.denselayer19.norm2.weight True\n",
            "features.denseblock3.denselayer19.norm2.bias True\n",
            "features.denseblock3.denselayer19.conv2.weight True\n",
            "features.denseblock3.denselayer20.norm1.weight True\n",
            "features.denseblock3.denselayer20.norm1.bias True\n",
            "features.denseblock3.denselayer20.conv1.weight True\n",
            "features.denseblock3.denselayer20.norm2.weight True\n",
            "features.denseblock3.denselayer20.norm2.bias True\n",
            "features.denseblock3.denselayer20.conv2.weight True\n",
            "features.denseblock3.denselayer21.norm1.weight True\n",
            "features.denseblock3.denselayer21.norm1.bias True\n",
            "features.denseblock3.denselayer21.conv1.weight True\n",
            "features.denseblock3.denselayer21.norm2.weight True\n",
            "features.denseblock3.denselayer21.norm2.bias True\n",
            "features.denseblock3.denselayer21.conv2.weight True\n",
            "features.denseblock3.denselayer22.norm1.weight True\n",
            "features.denseblock3.denselayer22.norm1.bias True\n",
            "features.denseblock3.denselayer22.conv1.weight True\n",
            "features.denseblock3.denselayer22.norm2.weight True\n",
            "features.denseblock3.denselayer22.norm2.bias True\n",
            "features.denseblock3.denselayer22.conv2.weight True\n",
            "features.denseblock3.denselayer23.norm1.weight True\n",
            "features.denseblock3.denselayer23.norm1.bias True\n",
            "features.denseblock3.denselayer23.conv1.weight True\n",
            "features.denseblock3.denselayer23.norm2.weight True\n",
            "features.denseblock3.denselayer23.norm2.bias True\n",
            "features.denseblock3.denselayer23.conv2.weight True\n",
            "features.denseblock3.denselayer24.norm1.weight True\n",
            "features.denseblock3.denselayer24.norm1.bias True\n",
            "features.denseblock3.denselayer24.conv1.weight True\n",
            "features.denseblock3.denselayer24.norm2.weight True\n",
            "features.denseblock3.denselayer24.norm2.bias True\n",
            "features.denseblock3.denselayer24.conv2.weight True\n",
            "features.transition3.norm.weight True\n",
            "features.transition3.norm.bias True\n",
            "features.transition3.conv.weight True\n",
            "features.denseblock4.denselayer1.norm1.weight True\n",
            "features.denseblock4.denselayer1.norm1.bias True\n",
            "features.denseblock4.denselayer1.conv1.weight True\n",
            "features.denseblock4.denselayer1.norm2.weight True\n",
            "features.denseblock4.denselayer1.norm2.bias True\n",
            "features.denseblock4.denselayer1.conv2.weight True\n",
            "features.denseblock4.denselayer2.norm1.weight True\n",
            "features.denseblock4.denselayer2.norm1.bias True\n",
            "features.denseblock4.denselayer2.conv1.weight True\n",
            "features.denseblock4.denselayer2.norm2.weight True\n",
            "features.denseblock4.denselayer2.norm2.bias True\n",
            "features.denseblock4.denselayer2.conv2.weight True\n",
            "features.denseblock4.denselayer3.norm1.weight True\n",
            "features.denseblock4.denselayer3.norm1.bias True\n",
            "features.denseblock4.denselayer3.conv1.weight True\n",
            "features.denseblock4.denselayer3.norm2.weight True\n",
            "features.denseblock4.denselayer3.norm2.bias True\n",
            "features.denseblock4.denselayer3.conv2.weight True\n",
            "features.denseblock4.denselayer4.norm1.weight True\n",
            "features.denseblock4.denselayer4.norm1.bias True\n",
            "features.denseblock4.denselayer4.conv1.weight True\n",
            "features.denseblock4.denselayer4.norm2.weight True\n",
            "features.denseblock4.denselayer4.norm2.bias True\n",
            "features.denseblock4.denselayer4.conv2.weight True\n",
            "features.denseblock4.denselayer5.norm1.weight True\n",
            "features.denseblock4.denselayer5.norm1.bias True\n",
            "features.denseblock4.denselayer5.conv1.weight True\n",
            "features.denseblock4.denselayer5.norm2.weight True\n",
            "features.denseblock4.denselayer5.norm2.bias True\n",
            "features.denseblock4.denselayer5.conv2.weight True\n",
            "features.denseblock4.denselayer6.norm1.weight True\n",
            "features.denseblock4.denselayer6.norm1.bias True\n",
            "features.denseblock4.denselayer6.conv1.weight True\n",
            "features.denseblock4.denselayer6.norm2.weight True\n",
            "features.denseblock4.denselayer6.norm2.bias True\n",
            "features.denseblock4.denselayer6.conv2.weight True\n",
            "features.denseblock4.denselayer7.norm1.weight True\n",
            "features.denseblock4.denselayer7.norm1.bias True\n",
            "features.denseblock4.denselayer7.conv1.weight True\n",
            "features.denseblock4.denselayer7.norm2.weight True\n",
            "features.denseblock4.denselayer7.norm2.bias True\n",
            "features.denseblock4.denselayer7.conv2.weight True\n",
            "features.denseblock4.denselayer8.norm1.weight True\n",
            "features.denseblock4.denselayer8.norm1.bias True\n",
            "features.denseblock4.denselayer8.conv1.weight True\n",
            "features.denseblock4.denselayer8.norm2.weight True\n",
            "features.denseblock4.denselayer8.norm2.bias True\n",
            "features.denseblock4.denselayer8.conv2.weight True\n",
            "features.denseblock4.denselayer9.norm1.weight True\n",
            "features.denseblock4.denselayer9.norm1.bias True\n",
            "features.denseblock4.denselayer9.conv1.weight True\n",
            "features.denseblock4.denselayer9.norm2.weight True\n",
            "features.denseblock4.denselayer9.norm2.bias True\n",
            "features.denseblock4.denselayer9.conv2.weight True\n",
            "features.denseblock4.denselayer10.norm1.weight True\n",
            "features.denseblock4.denselayer10.norm1.bias True\n",
            "features.denseblock4.denselayer10.conv1.weight True\n",
            "features.denseblock4.denselayer10.norm2.weight True\n",
            "features.denseblock4.denselayer10.norm2.bias True\n",
            "features.denseblock4.denselayer10.conv2.weight True\n",
            "features.denseblock4.denselayer11.norm1.weight True\n",
            "features.denseblock4.denselayer11.norm1.bias True\n",
            "features.denseblock4.denselayer11.conv1.weight True\n",
            "features.denseblock4.denselayer11.norm2.weight True\n",
            "features.denseblock4.denselayer11.norm2.bias True\n",
            "features.denseblock4.denselayer11.conv2.weight True\n",
            "features.denseblock4.denselayer12.norm1.weight True\n",
            "features.denseblock4.denselayer12.norm1.bias True\n",
            "features.denseblock4.denselayer12.conv1.weight True\n",
            "features.denseblock4.denselayer12.norm2.weight True\n",
            "features.denseblock4.denselayer12.norm2.bias True\n",
            "features.denseblock4.denselayer12.conv2.weight True\n",
            "features.denseblock4.denselayer13.norm1.weight True\n",
            "features.denseblock4.denselayer13.norm1.bias True\n",
            "features.denseblock4.denselayer13.conv1.weight True\n",
            "features.denseblock4.denselayer13.norm2.weight True\n",
            "features.denseblock4.denselayer13.norm2.bias True\n",
            "features.denseblock4.denselayer13.conv2.weight True\n",
            "features.denseblock4.denselayer14.norm1.weight True\n",
            "features.denseblock4.denselayer14.norm1.bias True\n",
            "features.denseblock4.denselayer14.conv1.weight True\n",
            "features.denseblock4.denselayer14.norm2.weight True\n",
            "features.denseblock4.denselayer14.norm2.bias True\n",
            "features.denseblock4.denselayer14.conv2.weight True\n",
            "features.denseblock4.denselayer15.norm1.weight True\n",
            "features.denseblock4.denselayer15.norm1.bias True\n",
            "features.denseblock4.denselayer15.conv1.weight True\n",
            "features.denseblock4.denselayer15.norm2.weight True\n",
            "features.denseblock4.denselayer15.norm2.bias True\n",
            "features.denseblock4.denselayer15.conv2.weight True\n",
            "features.denseblock4.denselayer16.norm1.weight True\n",
            "features.denseblock4.denselayer16.norm1.bias True\n",
            "features.denseblock4.denselayer16.conv1.weight True\n",
            "features.denseblock4.denselayer16.norm2.weight True\n",
            "features.denseblock4.denselayer16.norm2.bias True\n",
            "features.denseblock4.denselayer16.conv2.weight True\n",
            "features.norm5.weight True\n",
            "features.norm5.bias True\n",
            "classifier.weight True\n",
            "classifier.bias True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in densenet.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "for param in densenet.classifier.parameters():\n",
        "  param.requires_grad = True"
      ],
      "metadata": {
        "id": "j22gd5Zox1sj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(model=densenet, num_epochs=2, learning_rate=0.0003)"
      ],
      "metadata": {
        "id": "mzhXSgtIyE8z",
        "outputId": "c14ec3cc-72d6-47da-b297-4c6afbce7408",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla T4\n",
            "\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 196/196 [00:22<00:00,  8.62it/s, Epoch=0, Train_Loss=2]\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 40/40 [00:04<00:00,  9.00it/s, Epoch=0, Valid_Acc=40.6, Valid_Loss=1.74]\n",
            "Validation Accuracy Improved (0.0 ---> 40.64)\n",
            "\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 196/196 [00:22<00:00,  8.53it/s, Epoch=1, Train_Loss=1.62]\n",
            "100%|\u001b[36mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\u001b[0m| 40/40 [00:06<00:00,  6.15it/s, Epoch=1, Valid_Acc=45.5, Valid_Loss=1.59]\n",
            "Validation Accuracy Improved (40.64 ---> 45.55)\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "pytorch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e10a7834e18a47c0b5350514dbefc141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_425a70fc7920470286e2d7fc5b3785b2",
              "IPY_MODEL_9d52468c909148f798b964eff21286ce",
              "IPY_MODEL_7f9c82873cfe48bcaaa5e5d895ba41f7"
            ],
            "layout": "IPY_MODEL_8ae824e522c243eca9262b55fd1096d9"
          }
        },
        "425a70fc7920470286e2d7fc5b3785b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53f2203e0e264920a574872ac92e1d90",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3dffa4dc724e43c6a92790dc81dc3280",
            "value": ""
          }
        },
        "9d52468c909148f798b964eff21286ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a3ad1f038ab4619bab48bd20344be25",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c57ca9368a44e3d9370805903a73c06",
            "value": 0
          }
        },
        "7f9c82873cfe48bcaaa5e5d895ba41f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2205b3eee1364992853cc504b6235fd0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_93a639642be84e26a4f40f259a7287a7",
            "value": "â€‡0/0â€‡[00:00&lt;?,â€‡?it/s]"
          }
        },
        "8ae824e522c243eca9262b55fd1096d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f2203e0e264920a574872ac92e1d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dffa4dc724e43c6a92790dc81dc3280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a3ad1f038ab4619bab48bd20344be25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9c57ca9368a44e3d9370805903a73c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2205b3eee1364992853cc504b6235fd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93a639642be84e26a4f40f259a7287a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd330158b9d44f6b9c0ec39608c9fd9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52aae5dd9285401082a03657336b04e8",
              "IPY_MODEL_2a337064e486466e8e32d449d5b8fb20",
              "IPY_MODEL_9c801b9ff2f94a47b18a03ab8ebac783"
            ],
            "layout": "IPY_MODEL_673b8443090d4f8194e56cf8eb77abc5"
          }
        },
        "52aae5dd9285401082a03657336b04e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c51ade297134e929da8ff9bc26d2de9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ea45b3c0a27544fb881010cc342ec116",
            "value": "config.json:â€‡100%"
          }
        },
        "2a337064e486466e8e32d449d5b8fb20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cd6e523bd4c4fa99e7419f4e4525121",
            "max": 69770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dceaa0a0f2f147fb8028454f0b8ab8f0",
            "value": 69770
          }
        },
        "9c801b9ff2f94a47b18a03ab8ebac783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdc3d6432cb442b183c27fa62f837d58",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1fa6152a29884e289c8bac92cf9fd117",
            "value": "â€‡69.8k/69.8kâ€‡[00:00&lt;00:00,â€‡399kB/s]"
          }
        },
        "673b8443090d4f8194e56cf8eb77abc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c51ade297134e929da8ff9bc26d2de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea45b3c0a27544fb881010cc342ec116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cd6e523bd4c4fa99e7419f4e4525121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dceaa0a0f2f147fb8028454f0b8ab8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdc3d6432cb442b183c27fa62f837d58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fa6152a29884e289c8bac92cf9fd117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35827a48d993484d9382ce3cc829184b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf71a854f6804180a4fff128d7307fdc",
              "IPY_MODEL_d4a1920424b8491a99bee054ce861a18",
              "IPY_MODEL_bd73cf7a0283452baad04c0241c63347"
            ],
            "layout": "IPY_MODEL_b1b92c32af824951aeb06232e5c3bfe6"
          }
        },
        "bf71a854f6804180a4fff128d7307fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f309973c5624acbbfa497ab700d6b83",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dc82f3c833654770a0bf91aafa54f3c9",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "d4a1920424b8491a99bee054ce861a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dd93c08d42742cdaf125be57fb78a3f",
            "max": 14199388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e8110572e994eebb9a758c150efda94",
            "value": 14199388
          }
        },
        "bd73cf7a0283452baad04c0241c63347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b251b69bd4c7460384292a8b658ceab1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f653803ed3544d6bb2462bab3249e4ed",
            "value": "â€‡14.2M/14.2Mâ€‡[00:00&lt;00:00,â€‡23.8MB/s]"
          }
        },
        "b1b92c32af824951aeb06232e5c3bfe6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f309973c5624acbbfa497ab700d6b83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc82f3c833654770a0bf91aafa54f3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dd93c08d42742cdaf125be57fb78a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e8110572e994eebb9a758c150efda94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b251b69bd4c7460384292a8b658ceab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f653803ed3544d6bb2462bab3249e4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}