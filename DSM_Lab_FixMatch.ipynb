{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valy3124/Data-Science-Medical-DL/blob/main/DSM_Lab_FixMatch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSM Lab 6\n",
        "## Semi-Supervised Learning with FixMatch\n",
        "\n",
        "In this lab, we will explore the implementation of FixMatch, a method for performing semi-supervised learning.\n",
        "\n",
        "We will perform our training on a fraction of CIFAR10, a dataset of natural images\n",
        "\n",
        "You can find the original paper here: FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence (https://arxiv.org/abs/2001.07685)\n",
        "\n"
      ],
      "metadata": {
        "id": "LIfzH1M7IZMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.models import resnet18\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import RandomSampler, SequentialSampler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "uxxtw2ThIrZJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_epoch(model, dataloader, device, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0.0\n",
        "    dataset_size = 0\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n",
        "    for step, (images, labels) in bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(images)\n",
        "        loss = criterion(pred, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = np.round(total_train_loss / dataset_size, 2)\n",
        "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss)\n",
        "\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "def valid_epoch(model, dataloader, device, criterion, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    total_val_loss = 0.0\n",
        "    dataset_size = 0\n",
        "\n",
        "    correct = 0\n",
        "\n",
        "    bar = tqdm(enumerate(dataloader), total=len(dataloader), colour='cyan', file=sys.stdout)\n",
        "    for step, (images, labels) in bar:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        pred = model(images)\n",
        "        loss = criterion(pred, labels)\n",
        "\n",
        "        _, predicted = torch.max(pred, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        total_val_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = np.round(total_val_loss / dataset_size, 2)\n",
        "\n",
        "        accuracy = np.round(100 * correct / dataset_size, 2)\n",
        "\n",
        "        bar.set_postfix(Epoch=epoch, Valid_Acc=accuracy, Valid_Loss=epoch_loss)\n",
        "\n",
        "    return accuracy, epoch_loss\n",
        "\n",
        "def run_training(model, trainloader, testloader, criterion, optimizer, num_epochs):\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    top_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_loss = train_epoch(model, trainloader, device, optimizer, criterion, epoch)\n",
        "        with torch.no_grad():\n",
        "            val_accuracy, val_loss = valid_epoch(model, testloader, device, criterion, epoch)\n",
        "            if val_accuracy > top_accuracy:\n",
        "                print(f\"Validation Accuracy Improved ({top_accuracy} ---> {val_accuracy})\")\n",
        "                top_accuracy = val_accuracy\n",
        "        print()"
      ],
      "metadata": {
        "id": "RVVPuvbzIteq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't touch this for now.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Let's just use 10% of the data to make it harder\n",
        "from collections import defaultdict\n",
        "indices_per_class = defaultdict(list)\n",
        "for i in range(len(cifar_trainset)):\n",
        "  _, class_label = cifar_trainset[i]\n",
        "  indices_per_class[class_label].append(i)\n",
        "\n",
        "labeled_indices = []\n",
        "unlabeled_indices = []\n",
        "for class_name, indices in indices_per_class.items():\n",
        "  labeled_indices.extend(indices[:int(0.1 * len(indices))]) # 10% labeled\n",
        "  unlabeled_indices.extend(indices[int(0.1 * len(indices)):]) # 90% unlabeled\n",
        "\n",
        "cifar_labeled_trainset = torch.utils.data.Subset(dataset = cifar_trainset, indices = labeled_indices)\n",
        "\n",
        "cifar_labeled_trainloader = DataLoader(cifar_labeled_trainset, batch_size=64, shuffle=True)\n",
        "cifar_testloader = DataLoader(cifar_testset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB2K6AkoIyLd",
        "outputId": "0a8a73c1-c9d2-4b7b-f703-03cce377312b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline: Training just with the supervised data."
      ],
      "metadata": {
        "id": "n30DeNSgKQfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained = False) # let's initialize a ResNet18 from scratch and pretrain it ourselves\n",
        "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=10, bias=True)\n",
        "\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam is an improved gradient descent algorithm\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfMgwZewJddY",
        "outputId": "220dafce-70b6-402a-8de5-1582f895849b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(model, cifar_labeled_trainloader, cifar_testloader, criterion = criterion, optimizer = optimizer, num_epochs = epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC230FhoJlgF",
        "outputId": "c6034f6c-9e70-4934-9889-69292160a4d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla T4\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:05<00:00, 15.49it/s, Epoch=0, Train_Loss=1.87]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 40.25it/s, Epoch=0, Valid_Acc=40, Valid_Loss=1.61]\n",
            "Validation Accuracy Improved (0.0 ---> 39.95)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:03<00:00, 25.30it/s, Epoch=1, Train_Loss=1.5]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:05<00:00, 30.83it/s, Epoch=1, Valid_Acc=46.5, Valid_Loss=1.49]\n",
            "Validation Accuracy Improved (39.95 ---> 46.54)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:03<00:00, 25.13it/s, Epoch=2, Train_Loss=1.32]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 40.98it/s, Epoch=2, Valid_Acc=39.5, Valid_Loss=1.83]\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:03<00:00, 21.70it/s, Epoch=3, Train_Loss=1.18]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 41.41it/s, Epoch=3, Valid_Acc=46.3, Valid_Loss=1.57]\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:03<00:00, 25.06it/s, Epoch=4, Train_Loss=0.98]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:04<00:00, 38.76it/s, Epoch=4, Valid_Acc=46.7, Valid_Loss=1.67]\n",
            "Validation Accuracy Improved (46.54 ---> 46.73)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:03<00:00, 22.83it/s, Epoch=5, Train_Loss=0.86]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 42.10it/s, Epoch=5, Valid_Acc=50.5, Valid_Loss=1.55]\n",
            "Validation Accuracy Improved (46.73 ---> 50.46)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:03<00:00, 25.02it/s, Epoch=6, Train_Loss=0.69]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:04<00:00, 35.51it/s, Epoch=6, Valid_Acc=48.3, Valid_Loss=1.71]\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:03<00:00, 25.03it/s, Epoch=7, Train_Loss=0.6]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 42.09it/s, Epoch=7, Valid_Acc=51.9, Valid_Loss=1.63]\n",
            "Validation Accuracy Improved (50.46 ---> 51.86)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:03<00:00, 23.53it/s, Epoch=8, Train_Loss=0.46]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:04<00:00, 37.04it/s, Epoch=8, Valid_Acc=51.1, Valid_Loss=1.78]\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 79/79 [00:03<00:00, 24.78it/s, Epoch=9, Train_Loss=0.33]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 40.79it/s, Epoch=9, Valid_Acc=51.2, Valid_Loss=1.91]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results suck. Let's make them better.\n",
        "\n",
        "First, let's define a set of weak and strong augmentations."
      ],
      "metadata": {
        "id": "BU9jGYtwKJfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weak_transforms = transforms.Compose([\n",
        "    # TODO add random horizontal flips\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # TODO add random crops (use padding=int(32*0.125))\n",
        "    transforms.RandomCrop(32, padding=int(32*0.125)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "]) # weak transforms are just random shifting and flipping\n",
        "\n",
        "strong_transforms = transforms.Compose([\n",
        "    # TODO add random horizontal flips\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    # TODO add random crops (use padding=int(32*0.125))\n",
        "    transforms.RandomCrop(32, padding=int(32*0.125)),\n",
        "    # TODO add color jitter\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    # TODO add random grayscale with some small probability\n",
        "    transforms.RandomGrayscale(p=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "class TransformFixMatch(object):\n",
        "    def __init__(self, weak, strong):\n",
        "        self.weak = weak\n",
        "        self.strong = strong\n",
        "\n",
        "    def __call__(self, x):\n",
        "        weak = self.weak(x)\n",
        "        strong = self.strong(x)\n",
        "\n",
        "        return weak, strong\n",
        "\n",
        "class CIFAR10SSL(datasets.CIFAR10):\n",
        "    def __init__(self, root, indexs, train=True, transform=None, target_transform=None, download=False):\n",
        "        super().__init__(root, train=train, transform=transform, target_transform=target_transform, download=download)\n",
        "        if indexs is not None:\n",
        "            self.data = self.data[indexs]\n",
        "            self.targets = np.array(self.targets)[indexs]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "        img = Image.fromarray(img)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n"
      ],
      "metadata": {
        "id": "xgF5v90TJtzm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the new transforms\n",
        "cifar_labeled_trainset = CIFAR10SSL(root='./data', indexs = labeled_indices, train=True, transform = weak_transforms)\n",
        "cifar_unlabeled_trainset = CIFAR10SSL(root='./data', indexs = unlabeled_indices, train=True, transform=TransformFixMatch(weak = weak_transforms, strong = strong_transforms))\n",
        "cifar_testset = datasets.CIFAR10(root='./data', train=False, transform = val_transforms, download=False)\n",
        "\n",
        "# One training batch contains 1/8 labeled data and 7/8 unlabeled data.\n",
        "cifar_labeled_trainloader = DataLoader(cifar_labeled_trainset, batch_size=64, sampler = RandomSampler(cifar_labeled_trainset))\n",
        "cifar_unlabeled_trainloader = DataLoader(cifar_unlabeled_trainset, batch_size=7 * 64, sampler = RandomSampler(cifar_unlabeled_trainset))\n",
        "\n",
        "# Test set is all labeled\n",
        "cifar_testloader = DataLoader(cifar_testset, batch_size=64, shuffle = False)"
      ],
      "metadata": {
        "id": "xiBDV-wfMaL5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fixmatch_epoch(model, labeled_dataloader, unlabeled_dataloader, device, optimizer, epoch):\n",
        "    criterion_labeled = nn.CrossEntropyLoss()\n",
        "    criterion_unlabeled = nn.CrossEntropyLoss(reduction='none') # loss per example\n",
        "\n",
        "    # TODO try out some other values here?\n",
        "    threshold = 0.90 # predictions smaller than 90% confidence are filtered.\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    total_train_loss = 0.0\n",
        "    dataset_size = 0\n",
        "\n",
        "    bar = tqdm(enumerate(unlabeled_dataloader), total=len(unlabeled_dataloader), colour='cyan', file=sys.stdout)\n",
        "\n",
        "    labeled_iterator = iter(labeled_dataloader)\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for step, (unlabeled_images, _) in bar:\n",
        "        unlabeled_images_weak, unlabeled_images_strong = unlabeled_images\n",
        "\n",
        "        unlabeled_images_weak = unlabeled_images_weak.to(device)\n",
        "        unlabeled_images_strong = unlabeled_images_strong.to(device)\n",
        "        try:\n",
        "          labeled_images, labels = next(labeled_iterator)\n",
        "        except StopIteration as e:\n",
        "          labeled_iterator = iter(labeled_dataloader)\n",
        "          labeled_images, labels = next(labeled_iterator)\n",
        "\n",
        "        labeled_images = labeled_images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred_labeled = model(labeled_images)\n",
        "\n",
        "        # get pseudo-labels, don't propagate gradients\n",
        "        with torch.no_grad():\n",
        "          pred_weak = model(unlabeled_images_weak)\n",
        "\n",
        "          # get confidence as a probability\n",
        "          pred_weak_confidence = torch.nn.functional.softmax(pred_weak, dim = -1)\n",
        "          max_values, max_indices = torch.max(pred_weak_confidence, dim = -1)\n",
        "\n",
        "          # filter out unconfident predictions\n",
        "          fixmatch_mask = (max_values > threshold).float()\n",
        "\n",
        "        # TODO other things to try out\n",
        "        # add mixup between labeled data and unlabeled data\n",
        "        # (interpolate labeled images with strongly augmented unlabeled images and between corresponding true labels and pseudo-labels)\n",
        "        # mixup: BEYOND EMPIRICAL RISK MINIMIZATION https://arxiv.org/pdf/1710.09412\n",
        "\n",
        "        # TODO (more complicated)\n",
        "        # some pseudo-labels might be wrong and stay wrong throughout training\n",
        "        # maybe figure out which ones are wrong by looking at training dynamics\n",
        "        # Identifying Mislabeled Data using the Area Under the Margin Ranking https://arxiv.org/pdf/2001.10528\n",
        "        # MarginMatch: Improving Semi-Supervised Learning with Pseudo-Margins https://arxiv.org/pdf/2308.09037\n",
        "\n",
        "        pred_strong = model(unlabeled_images_strong)\n",
        "\n",
        "        # loss for labeled images (nothing special, crossentropy between true labels and preds)\n",
        "        loss_labeled = criterion_labeled(pred_labeled, labels)\n",
        "\n",
        "        # loss for unlabeled: crossentropy between high-confidence pseudo-labels on weak augmentations and preds on strong augmentations\n",
        "        # fixmatch_mask filters out unconfident pseudo-labels\n",
        "        loss_consistency = criterion_unlabeled(pred_strong, max_indices) * fixmatch_mask\n",
        "        loss_consistency = loss_consistency.mean()\n",
        "\n",
        "        loss = loss_labeled + loss_consistency\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        bar.set_postfix(Epoch=epoch, LabeledLoss=loss_labeled.item(), ConsistencyLoss = loss_consistency.item(), FractionMasked=(1 - fixmatch_mask.float().mean()).item())\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def run_training_fixmatch(model, labeled_trainloader, unlabeled_trainloader, testloader, optimizer, num_epochs):\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    top_accuracy = 0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        train_loss = train_fixmatch_epoch(model, labeled_trainloader, unlabeled_trainloader, device, optimizer, epoch)\n",
        "        with torch.no_grad():\n",
        "            val_accuracy, val_loss = valid_epoch(model, testloader, device, criterion, epoch)\n",
        "            if val_accuracy > top_accuracy:\n",
        "                print(f\"Validation Accuracy Improved ({top_accuracy} ---> {val_accuracy})\")\n",
        "                top_accuracy = val_accuracy\n",
        "        print()"
      ],
      "metadata": {
        "id": "ON9y5_JJOf4e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 10 # usually train for way longer.\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained = False) # let's initialize a ResNet18 from scratch and train it ourselves\n",
        "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=10, bias=True)\n",
        "\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam is an improved gradient descent algorithm\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "IBHO5fQgUyYA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_training_fixmatch(\n",
        "    model,\n",
        "    labeled_trainloader = cifar_labeled_trainloader,\n",
        "    unlabeled_trainloader = cifar_unlabeled_trainloader,\n",
        "    testloader = cifar_testloader,\n",
        "    optimizer = optimizer,\n",
        "    num_epochs = epochs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFgPflpLVV40",
        "outputId": "87e29781-1e96-4f59-aa13-a86d8e2a4d9f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Using GPU: Tesla T4\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:16<00:00,  1.32it/s, ConsistencyLoss=0, Epoch=0, FractionMasked=1, LabeledLoss=1.76]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:04<00:00, 36.33it/s, Epoch=0, Valid_Acc=40.2, Valid_Loss=1.63]\n",
            "Validation Accuracy Improved (0.0 ---> 40.2)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:16<00:00,  1.32it/s, ConsistencyLoss=0, Epoch=1, FractionMasked=1, LabeledLoss=1.61]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 41.62it/s, Epoch=1, Valid_Acc=43.9, Valid_Loss=1.53]\n",
            "Validation Accuracy Improved (40.2 ---> 43.88)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:16<00:00,  1.31it/s, ConsistencyLoss=0.0281, Epoch=2, FractionMasked=0.96, LabeledLoss=1.48]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:04<00:00, 35.00it/s, Epoch=2, Valid_Acc=43.5, Valid_Loss=1.56]\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:17<00:00,  1.31it/s, ConsistencyLoss=0.00806, Epoch=3, FractionMasked=0.97, LabeledLoss=1.28]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 41.17it/s, Epoch=3, Valid_Acc=44.1, Valid_Loss=1.56]\n",
            "Validation Accuracy Improved (43.88 ---> 44.13)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:17<00:00,  1.30it/s, ConsistencyLoss=0.0452, Epoch=4, FractionMasked=0.925, LabeledLoss=1.23]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:04<00:00, 37.78it/s, Epoch=4, Valid_Acc=48.8, Valid_Loss=1.41]\n",
            "Validation Accuracy Improved (44.13 ---> 48.76)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:16<00:00,  1.32it/s, ConsistencyLoss=0.00711, Epoch=5, FractionMasked=0.95, LabeledLoss=1.21]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 42.22it/s, Epoch=5, Valid_Acc=53.8, Valid_Loss=1.31]\n",
            "Validation Accuracy Improved (48.76 ---> 53.79)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:16<00:00,  1.31it/s, ConsistencyLoss=0.0862, Epoch=6, FractionMasked=0.885, LabeledLoss=1.32]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 41.49it/s, Epoch=6, Valid_Acc=55.3, Valid_Loss=1.27]\n",
            "Validation Accuracy Improved (53.79 ---> 55.34)\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:16<00:00,  1.32it/s, ConsistencyLoss=0.0475, Epoch=7, FractionMasked=0.84, LabeledLoss=1.36]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 39.94it/s, Epoch=7, Valid_Acc=55.3, Valid_Loss=1.32]\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:16<00:00,  1.32it/s, ConsistencyLoss=0.0546, Epoch=8, FractionMasked=0.855, LabeledLoss=1.23]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:03<00:00, 41.66it/s, Epoch=8, Valid_Acc=52.1, Valid_Loss=1.46]\n",
            "\n",
            "100%|\u001b[36m██████████\u001b[0m| 101/101 [01:16<00:00,  1.32it/s, ConsistencyLoss=0.0345, Epoch=9, FractionMasked=0.81, LabeledLoss=1.12]\n",
            "100%|\u001b[36m██████████\u001b[0m| 157/157 [00:04<00:00, 36.09it/s, Epoch=9, Valid_Acc=58.9, Valid_Loss=1.2]\n",
            "Validation Accuracy Improved (55.34 ---> 58.89)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T_sm1TXLVs7G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}